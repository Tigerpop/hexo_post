---
layout: posts
title: æœ¬åœ°éƒ¨ç½²Deepseekå®ç°RAGå¹¶è”ç½‘æœç´¢
date: 2025-4-2 09:08:18
description: "è¿™æ˜¯æ–‡ç« å¼€å¤´ï¼Œæ˜¾ç¤ºåœ¨ä¸»é¡µé¢ï¼Œè¯¦æƒ…è¯·ç‚¹å‡»æ­¤å¤„ã€‚"
categories: 
- "æœºå™¨å­¦ä¹ "
tags:
- "docker"
- "docker compose"
- "NVIDIA Container Toolkit"
- "nvidia-cuda-toolkit"
- "æœç´¢å¼•æ“"
- "åå‘ä»£ç†"
- "SearXNG"
- "ollama"
- "anythingllm"
- "Nignx proxy manager"
- "openwebUI"
- "modelscope"
- "vllm"
- "å®¹å™¨"
- "deepseek"
- "é›†ç¾¤"
- "swarm"
- "Ray"
- "åµŒå…¥æ¨¡å‹"
- "Text Embeddings Inference"
- "bge-large-zh-v1.5"
---





æœ¬åœ°éƒ¨ç½²Deepseekæœ‰å‡ ç§ç»å…¸çš„åšæ³•ï¼Œæœ‰å€ŸåŠ©ollamaå®ç°ä¹Ÿæœ‰ç›´æ¥ä¸‹è½½å„ç§å¯¹åº”æ¨¡å‹åˆ°æœ¬åœ°ç”¨vllmè°ƒç”¨ç­‰ã€‚æˆ‘ä¸ºäº†ä½¿ç”¨å’Œéƒ¨ç½²æ–¹ä¾¿ï¼Œå†³å®šä½¿ç”¨dockeréƒ¨ç½²å®ç°ã€‚

ä½¿ç”¨å¤šç§æ–¹æ¡ˆéƒ¨ç½²å‰ï¼Œéœ€è¦å…ˆåšå¥½å‡†å¤‡å·¥ä½œã€‚

# ä¸€ã€å‰æœŸå‡†å¤‡

## 1ã€ç³»ç»Ÿã€å­˜å‚¨åŠé©±åŠ¨æƒ…å†µ

æˆ‘ä¹‹å‰æ˜¯ubuntu20.04çš„ç³»ç»Ÿï¼ŒLinuxæ ¸å¿ƒä¹Ÿæ˜¯è€ç‰ˆæœ¬çš„ï¼Œä½†æ˜¯Nvidiaé©±åŠ¨å’Œcondaç­‰ç¯å¢ƒä¸æƒ³å˜åŠ¨è¿˜æœ‰å¾ˆå¤šæ•°æ®ä¸æ–¹ä¾¿æŒªï¼Œæ‰€ä»¥é€‰æ‹©äº†ä½¿ç”¨å‘½ä»¤åå°å‡çº§æˆäº†ä¸‹é¢çš„ç‰ˆæœ¬ï¼ˆå¤§çº¦3å°æ—¶ï¼‰ï¼Œä¸ºäº†æ–¹ä¾¿ç›´æ¥ä½¿ç”¨dockerã€‚ä»¥ä¸‹æ˜¯å‡çº§å®Œæˆåæˆ‘çš„æœºå™¨æƒ…å†µã€‚

```sh
(base) cys@cysserver:~$ lsb_release -a 
No LSB modules are available.
Distributor ID:	Ubuntu
Description:	Ubuntu 24.04.2 LTS
Release:	24.04
Codename:	noble
(base) cys@cysserver:~$ uname -r 
6.8.0-53-generic

(base) cys@cysserver:~$ free -h 
               total        used        free      shared  buff/cache   available
Mem:           503Gi       5.9Gi       456Gi       7.3Mi        44Gi       497Gi
Swap:          8.0Gi          0B       8.0Gi


(base) cys@cysserver:~$ nvidia-smi 
Fri Feb 28 06:36:49 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 3090        Off |   00000000:47:00.0 Off |                  N/A |
| 41%   27C    P8             22W /  350W |       4MiB /  24576MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA GeForce RTX 3090        Off |   00000000:5E:00.0 Off |                  N/A |
| 41%   25C    P8             25W /  350W |       4MiB /  24576MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
```

![å¾®ä¿¡å›¾ç‰‡_20250228144008](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228144008.png)



## 2ã€å›½å†…å®‰è£…docker

### 2.1ã€å®‰è£…docker

```sh
# åˆ é™¤
sudo apt-get purge docker-ce docker-ce-cli containerd.io docker-buildx-plugin
sudo rm -rf /var/lib/docker
sudo rm -rf /var/lib/containerd
sudo rm -rf /etc/docker

# å®‰è£…
curl -fsSL https://get.docker.com | sudo sh
    # æˆ–è€…
    sudo apt-get update
    sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin
    # æˆ–è€…
    sudo sed -i 's/noble/jammy/g' /etc/apt/sources.list.d/docker.list
    sudo apt update
    sudo apt install docker-ce docker-ce-cli containerd.io docker-buildx-plugin

# é…ç½®Dockerç¯å¢ƒ
    # æ·»åŠ ç”¨æˆ·åˆ°dockerç»„
    sudo usermod -aG docker $USER
    newgrp docker  # åˆ·æ–°ç»„æƒé™
  	# é…ç½®é•œåƒåŠ é€Ÿå™¨ï¼ˆå›½å†…å»ºè®®ï¼‰
    vim /etc/docker/daemon.json
    ---------------------------------------------------
    {
      "registry-mirrors": [
        "https://docker.m.daocloud.io"
      ]
    }
    ---------------------------------------------------
    æˆ–
    ---------------------------------------------------
    {
      "registry-mirrors": [
        "https://docker.m.daocloud.io",
        "https://mirror.ccs.tencentyun.com",
        "https://func.ink",
        "https://proxy.1panel.live",
        "https://docker.zhai.cm"
      ]
    }
    ---------------------------------------------------
    
sudo systemctl daemon-reload
sudo systemctl enable docker
sudo systemctl restart docker

# æ£€éªŒå›½å†…æ˜¯å¦å¯ä»¥æ­£å¸¸æ‹‰å–
docker pull busybox

```

### 2.2ã€å®‰è£…docker-compose

å®˜æ–¹æ–‡æ¡£ï¼š    https://docs.docker.com/compose/install/

```sh
# æ’ä»¶æ–¹å¼å®‰è£…
sudo apt-get install docker-compose-plugin

# æ’ä»¶æ–¹å¼å®‰è£… æŸ¥çœ‹docker composeç‰ˆæœ¬
docker compose version
docker compose -v
```

### 

## 3ã€Docker è°ƒç”¨å®¿ä¸»æœºNvidiaå¡

### 3.1ã€å®‰è£…NVIDIA Container Toolkit NVIDIAå®¹å™¨å·¥å…·åŒ…

å‚è€ƒ ï¼šhttps://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html
https://blog.csdn.net/dw14132124/article/details/140534628

```sh
    curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
    curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

    sudo apt-get update

    sudo apt-get install -y nvidia-container-toolkit
```

ç»“åˆä¸Šé¢è§£å†³Docker CEçš„æ­¥éª¤ï¼Œå¯èƒ½ä¼šå¯¼è‡´ docker åœ¨å›½å†…æ‹‰å–ä¸åˆ°é•œåƒçš„æƒ…å†µï¼Œéœ€è¦æŒ‰ç…§ä¸‹é¢å†æä¸€ä¸‹ã€‚

```sh
# åˆ›å»º/ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼ˆæ³¨æ„ JSON æ ¼å¼ï¼‰
sudo vim /etc/docker/daemon.json

# ç²˜è´´ä»¥ä¸‹å†…å®¹ï¼ˆæ¨èç»„åˆå¤šä¸ªé•œåƒæºï¼‰
{
  "registry-mirrors": [
    "https://docker.m.daocloud.io",
    "https://mirror.ccs.tencentyun.com",
    "https://func.ink",
    "https://proxy.1panel.live",
    "https://docker.zhai.cm"
  ]
}

sudo systemctl daemon-reload
sudo systemctl enable docker
sudo systemctl restart docker

cat /etc/docker/daemon.json
# â€‹é¢„æœŸé…ç½®ï¼šåŒ…å« nvidia è¿è¡Œæ—¶å®šä¹‰ï¼ˆå¿…é¡»å­—æ®µï¼‰ï¼š
json
{
  "runtimes": {
    "nvidia": {
      "path": "nvidia-container-runtime",
      "runtimeArgs": []
    }
  }
}
# è‹¥ç¼ºå¤±ï¼Œæ‰§è¡Œ sudo nvidia-ctk runtime configure --runtime=docker è‡ªåŠ¨ä¿®å¤


# æ£€éªŒå›½å†…æ˜¯å¦å¯ä»¥æ­£å¸¸æ‹‰å–
docker pull busybox
docker pull nvidia/cuda:12.0.1-base-ubuntu22.04
```

æ£€æŸ¥ docker èƒ½ä¸èƒ½æ­£å¸¸ä½¿ç”¨ Nvidiaçš„GPU

```sh
# çœ‹çœ‹åº”è¯¥è¦ä¸æ˜¯ç©ºçš„ã€‚
dpkg -l | grep nvidia-container-toolkit

# å®˜æ–¹é•œåƒæ ‡ç­¾è§„åˆ™ä¸º "ä¸»ç‰ˆæœ¬-å­ç‰ˆæœ¬-åŸºç¡€ç¯å¢ƒ"
# æ‹‰å– CUDA 12.0.1 å¼€å‘é•œåƒ
docker pull nvidia/cuda:12.0.1-devel-ubuntu22.04

# æ£€æŸ¥æµ‹è¯•ï¼Œè¿è¡Œä¸€ä¸ªä¸´æ—¶å®¹å™¨ï¼Œæ˜¾ç¤ºåº”è¯¥æ˜¯å’Œ å®¿ä¸»æœº ä¸€æ¨¡ä¸€æ ·æ‰OKã€‚
docker run --rm --gpus all nvidia/cuda:12.0.1-devel-ubuntu22.04 nvidia-smi

docker run --rm --gpus all nvidia/cuda:12.0.1-devel-ubuntu22.04 nvcc --version

# å¯ä»¥é¢å¤–æµ‹è¯•ã€‚
#docker run --rm --gpus all nvidia/cuda:12.0.1-devel-ubuntu22.04 /bin/bash -c \
"apt update && apt install -y cuda-samples-12-0 && \
cd /usr/local/cuda/samples/0_Simple/vectorAdd && make && ./vectorAdd"
# æˆåŠŸæ ‡å¿—ï¼šè¾“å‡º Test PASSED
```

### 3.2ã€nvidia-docker ä¸ NVIDIA Container Toolkit çš„å…³ç³»

nvidia-docker ä¸ NVIDIA Container Toolkit çš„å…³ç³»ï¼š
        NVIDIA Container Toolkit çš„å®šä½NVIDIA Container Toolkit æ˜¯ä¸€å¥—å·¥å…·é›†åˆï¼ŒåŒ…å« nvidia-container-runtimeã€libnvidia-container ç­‰ç»„ä»¶ï¼Œç”¨äºå®ç°å®¹å™¨ä¸ GPU çš„æ·±åº¦é›†æˆã€‚å®ƒå–ä»£äº†æ—§ç‰ˆ nvidia-docker çš„æ ¸å¿ƒåŠŸèƒ½ã€‚
æ˜¯å¦éœ€è¦å•ç‹¬å®‰è£… nvidia-dockerï¼Ÿ
		Docker â‰¥19.03 ç‰ˆæœ¬ï¼šæ— éœ€å®‰è£… nvidia-dockerã€‚ç›´æ¥é€šè¿‡ Docker çš„ --gpus å‚æ•°å³å¯è°ƒç”¨ GPUï¼ˆä¾‹å¦‚ docker run --gpus all ...ï¼‰ï¼Œåº•å±‚ç”± NVIDIA Container Toolkit æä¾›æ”¯æŒã€‚æ—§ç‰ˆ Dockerï¼šéœ€å®‰è£… nvidia-docker2 åŒ…ä½œä¸ºæ’ä»¶ï¼Œä»¥å…¼å®¹ GPU è°ƒç”¨ã€‚

### 3.3ã€å®¿ä¸»æœºå®‰è£…nvidia-cuda-toolkit

```sh
# nvcc --version å¦‚æœæ²¡æœ‰å°±å¦‚ä¸‹å®‰è£…ã€‚
# sudo apt update 
# sudo apt install nvidia-cuda-toolkit
vim hello.cu
# _____________________________ hello.cu ____________________________________
#include <cuda_runtime.h>
#include <stdio.h>

__global__ void hello() {
    printf("Hello from GPU!\n");
}

int main() {
    hello<<<1,1>>>();
    cudaDeviceSynchronize();
    return 0;
}
# _____________________________ hello.cu ____________________________________
nvcc --version #  release 12.0, V12.0.140  Build cuda_12.0.r12.0/compiler.32267302_0
nvcc -o hello hello.cu -arch=sm_86 && ./hello 
# è¾“å‡º Hello from GPU! ç®—æˆåŠŸã€‚
```

### 



# äºŒã€è‡ªå»ºæœç´¢å¼•æ“

æ— è®ºæ˜¯ `DuckDuckGo` è¿˜æ˜¯ `Google Search Engine`ï¼Œéƒ½éœ€è¦ç§‘å­¦ä¸Šç½‘æ‰èƒ½æ­£å¸¸ä½¿ç”¨ã€‚

æ‰€ä»¥æˆ‘ä»¬å°±è¦è‡ªå·±æ­å»ºæœ¬åœ°çš„æœç´¢å¼•æ“ã€‚

## 1ã€SearXNG æœç´¢å¼•æ“æœ¬åœ°éƒ¨ç½²ï¼ˆäºŒé€‰ä¸€ï¼‰

### 1.1ã€Docker composeç‰ˆæœ¬ï¼ˆå¯æµè§ˆå™¨ä½¿ç”¨ï¼Œä¸å¯è¢«AnythingLLM/open webUIè°ƒç”¨ï¼‰

æˆ‘ä»¬è¿˜æ˜¯ç”¨dockerç‰ˆæœ¬çš„ï¼Œæ–¹ä¾¿ï¼š 

  https://github.com/searxng/searxng-docker
  https://docs.searxng.org/
  https://github.com/searxng/searxng/blob/master/searx/settings.yml

```sh
# æä¸ªå­˜é¡¹ç›®çš„æ–‡ä»¶å¤¹ï¼Œç„¶åæ‰§è¡Œä¸‹é¢æ“ä½œ
git clone https://github.com/searxng/searxng-docker.git
cd searxng-docker

# ç¼–è¾‘.envæ–‡ä»¶ä»¥è®¾ç½®ä¸»æœºåå’Œç”µå­é‚®ä»¶
# ä¸»æœºåå¯ä»¥å†™åŸŸåæˆ–è€…æœåŠ¡å™¨IPï¼Œæˆ‘è¿™é‡Œå†™çš„ IP å’Œ Nginx Proxy Manageråå‘ä»£ç†ç•™çš„é‚®ç®±ã€‚

# ç”Ÿæˆå¯†é’¥ 
sed -i "s|ultrasecretkey|$(openssl rand -hex 32)|g" searxng/settings.yml

# æ ¹æ®éœ€è¦ç¼–è¾‘searchng/settings.yml

# åœ¨ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶ï¼Œæ‚¨å¿…é¡»ä»docker-compose.yamlæ–‡ä»¶ä¸­åˆ é™¤cap_dropï¼š- ALLï¼Œä»¥ä¾¿searchngæœåŠ¡æˆåŠŸåˆ›å»º/etc/searxng/uwsgi. iniã€‚è¿™æ˜¯å¿…è¦çš„ï¼Œå› ä¸ºcap_dropï¼š- ALLæŒ‡ä»¤å°†åˆ é™¤æ‰€æœ‰åŠŸèƒ½ï¼ŒåŒ…æ‹¬åˆ›å»ºuwsgi.iniæ–‡ä»¶æ‰€éœ€çš„åŠŸèƒ½ã€‚åœ¨ç¬¬ä¸€æ¬¡è¿è¡Œåï¼Œå‡ºäºå®‰å…¨åŸå› ï¼Œæ‚¨åº”è¯¥å°†cap_dropï¼š- ALLé‡æ–°æ·»åŠ åˆ°docker-compose.yamlæ–‡ä»¶ä¸­ã€‚

# åˆ é™¤docker-compose.yamlä¸­ä¸caddyç›¸å…³çš„éƒ¨åˆ†ï¼Œä¾‹å¦‚caddyæœåŠ¡åŠå…¶å·ã€‚

# å°†åå‘ä»£ç†æŒ‡å‘docker-compose.ymlä¸­ä¸ºsearchngæœåŠ¡è®¾ç½®çš„ç«¯å£ï¼ˆé»˜è®¤ä¸º8080ï¼‰


# é€šè¿‡ docker compose down å‘½ä»¤åœæ­¢å½“å‰è¿è¡Œçš„æ‰€æœ‰å®¹å™¨ï¼ŒåŒæ—¶æ¸…ç†ç½‘ç»œå’Œå®¹å™¨èµ„æºï¼ˆé»˜è®¤ä¿ç•™æ•°æ®å·ï¼‰
docker compose down
# ä½¿ç”¨ docker compose up -d é‡æ–°æ„å»ºå¹¶å¯åŠ¨å®¹å™¨ï¼ˆè‡ªåŠ¨åº”ç”¨æœ€æ–°é…ç½®ï¼‰
docker compose up -d
```

#### 1.1.1ã€yamlï¼š

`searxng/searxng-docker# cat docker-compose.yaml `

```yaml
version: "3.7"

services:
  #  caddy:
  #    container_name: caddy
  #    image: docker.io/library/caddy:2-alpine
  # network_mode: host
  # restart: unless-stopped
  # volumes:
  #   - ./Caddyfile:/etc/caddy/Caddyfile:ro
  #   - caddy-data:/data:rw
  #   - caddy-config:/config:rw
  # environment:
  #   - SEARXNG_HOSTNAME=${SEARXNG_HOSTNAME:-http://localhost}
  #   - SEARXNG_TLS=${LETSENCRYPT_EMAIL:-internal}
  # cap_drop:
  #   - ALL
  # cap_add:
  #   - NET_BIND_SERVICE
  # logging:
  #   driver: "json-file"
  #   options:
  #     max-size: "1m"
  #     max-file: "1"

  redis:
    container_name: redis
    image: docker.io/valkey/valkey:8-alpine
    command: valkey-server --save 30 1 --loglevel warning
    restart: unless-stopped
    networks:
      - searxng
    volumes:
      - valkey-data2:/data
    cap_drop:
      - ALL
    cap_add:
      - SETGID
      - SETUID
      - DAC_OVERRIDE
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"

  searxng:
    container_name: searxng
    image: docker.io/searxng/searxng:latest
    restart: unless-stopped
    networks:
      - searxng
    ports:
      - "0.0.0.0:8080:8080"   # ä»¥åè¦æ”¹ï¼Œæµ‹è¯•ç»™æœåŠ¡å™¨ä»¥å¤–çš„æœºå™¨æ˜¾ç¤ºæ‰è¿™æ ·å†™ã€‚
    volumes:
      - ./searxng:/etc/searxng:rw
    environment:
      - SEARXNG_BASE_URL=http://${SEARXNG_HOSTNAME:-localhost}/  # é’ˆå¯¹æˆ‘çš„æƒ…å†µä¿®æ”¹çš„ã€‚
      - UWSGI_WORKERS=${SEARXNG_UWSGI_WORKERS:-4}
      - UWSGI_THREADS=${SEARXNG_UWSGI_THREADS:-4}
#    cap_drop:            # ç¬¬ä¸€æ¬¡ æ³¨é‡Šè€Œå·²ï¼Œä¹‹åå¯åŠ¨ è®°å¾—æ‰“å¼€ ã€‚
#      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"

networks:
  searxng:

volumes:
  #caddy-data:
  #caddy-config:
  valkey-data2:
```

#### 1.1.2ã€yamlè§£é‡Šï¼š

```yaml
ports:
  - "127.0.0.1:8080:8080"
```

è¿™è¡¨ç¤ºå°†å®¹å™¨å†…éƒ¨çš„ 8080 ç«¯å£æ˜ å°„åˆ°å®¿ä¸»æœºçš„ 127.0.0.1 åœ°å€ï¼ˆå³ localhostï¼‰çš„ 8080 ç«¯å£ã€‚
**å«ä¹‰**ï¼šåªæœ‰åœ¨æœåŠ¡å™¨æœ¬æœºä¸Šè®¿é—® `127.0.0.1:8080` æ‰èƒ½çœ‹åˆ°æœåŠ¡ã€‚å¦‚æœä½ åœ¨ä¸æœåŠ¡å™¨åŒä¸€å±€åŸŸç½‘çš„ä¸ªäººç”µè„‘ä¸Šä½¿ç”¨æœåŠ¡å™¨ IPï¼ˆä¾‹å¦‚ `192.168.1.100:8080`ï¼‰è®¿é—®ï¼Œç”±äºæ˜ å°„åªç»‘å®šåœ¨ 127.0.0.1 ä¸Šï¼Œå¤–éƒ¨è®¾å¤‡æ— æ³•é€šè¿‡æœåŠ¡å™¨å¤–ç½‘ IP è®¿é—®åˆ°è¿™ä¸ªç«¯å£ã€‚
å¦‚æœä½ å¸Œæœ›å±€åŸŸç½‘å†…çš„å…¶ä»–è®¾å¤‡éƒ½èƒ½è®¿é—®ï¼Œå¯ä»¥å°†ç«¯å£æ˜ å°„ä¿®æ”¹ä¸ºï¼š

```yaml
ports:
  - "0.0.0.0:8080:8080"
```

ç¯å¢ƒå˜é‡

```yaml
environment:
  - SEARXNG_BASE_URL=https://${SEARXNG_HOSTNAME:-localhost}/
```

è¿™è¡¨ç¤ºé»˜è®¤ä½¿ç”¨ HTTPS åè®®ï¼Œå¹¶ä¸”å¦‚æœç¯å¢ƒå˜é‡ `SEARXNG_HOSTNAME` æ²¡æœ‰è®¾ç½®ï¼Œåˆ™ä½¿ç”¨ `localhost` ä½œä¸ºåŸŸåã€‚

å¦‚æœä½ çš„æƒ…å†µå’Œæˆ‘ä¸€æ ·ï¼š

- ä½ åœ¨å±€åŸŸç½‘å†…åšäº† DNS è§£æï¼Œä½†æ²¡æœ‰åœ¨å…¬ç½‘åš DNSã€‚

- ä½ è®¾ç½®äº†åå‘ä»£ç†ï¼Œä½†æ²¡æœ‰ TLSï¼ˆå³åªæä¾› HTTP è®¿é—®ï¼‰ã€‚

  å› æ­¤ï¼Œä½ åœ¨å±€åŸŸç½‘å†…é€šè¿‡ `http://å±€åŸŸç½‘çš„åŸŸå` æ¥è®¿é—®ã€‚
  ä¾‹å¦‚ï¼š

```yaml
environment:
  - SEARXNG_BASE_URL=http://${SEARXNG_HOSTNAME:-localhost}/
```

å¦‚æœä½ ä¸æƒ³ä½¿ç”¨åŸŸåï¼Œä¹Ÿå¯ä»¥ç›´æ¥ä½¿ç”¨æœåŠ¡å™¨çš„ IP åœ°å€ï¼Œæ¯”å¦‚ï¼š

```yaml
environment:
  - SEARXNG_BASE_URL=http://10.199.1.233/
```

è¿™é‡Œçš„ 10.199.1.233  å°±æ˜¯ä½ æœåŠ¡å™¨åœ¨å±€åŸŸç½‘å†…çš„ IP åœ°å€ã€‚

#### 1.1.3ã€ä¿®æ”¹setting.ymlé…ç½®

æ‰¾è‡ªå·±è¦æ·»åŠ çš„å†…å®¹å¤åˆ¶ä¸‹æ¥ï¼Œé»è´´è¿›é»˜è®¤çš„setting.ymlä¸­å°±è¡Œäº†ï¼Œè¿™æ ·å¥½åƒä¸è¡Œã€‚
é€‰ä¸­å›½å¤§é™†èƒ½ç”¨çš„engineã€‚

```yaml
# å‚è€ƒ https://github.com/searxng/searxng/blob/master/searx/settings.yml
```

ä»¥ä¸‹æ˜¯æˆ‘çš„ setting.yml æƒ…å†µ,åŠ äº†ä¸€ä¸ª json æ ¼å¼ å’Œ bing engineã€‚

```yaml
(base) cys@cysserver:~/docker_data/searxng/searxng-docker$ cat ./searxng/settings.yml
# see https://docs.searxng.org/admin/settings/settings.html#settings-use-default-settings
use_default_settings: true
server:
  # base_url is defined in the SEARXNG_BASE_URL environment variable, see .env and docker-compose.yml
  secret_key: "æˆ‘çš„å¯†é’¥"  # change this!
  limiter: false  #true  # can be disabled for a private instance
  image_proxy: true
ui:
  static_use_hash: true
redis:
  url: redis://redis:6379/0
engines:
  - name: 360search      # é€‚ç”¨äºä¸­å›½å¤§é™†
    engine: 360search
    shortcut: 360so
    disabled: false
  - name: bing
    engine: bing
    shortcut: bi
    disabled: false
  - name: sogou
    engine: sogou
    shortcut: sogou
    disabled: false
search:
  formats:
    - html
    - json  # è¦èƒ½jsonæ ¼å¼ï¼Œæ–¹ä¾¿è°ƒç”¨
```



#### 1.1.4ã€ç™»å½•searxngé¡µé¢æ”¹æœç´¢å¼•æ“ï¼š

å› ä¸ºå¤§é™†ä¸æ–¹ä¾¿ç”¨å¾ˆå¤šå¼•æ“ï¼Œä½ æ‡‚çš„ã€‚æ‰€ä»¥æˆ‘ä»¬ç”¨ ä¸­å›½å¤§é™†å¯ä»¥ç”¨çš„ bing è¿™äº›ã€‚

å…ˆç™»å½• http://IP:8080  åœ¨å³ä¸Šè§’é…ç½®ã€‚![é…ç½®](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E9%85%8D%E7%BD%AE.png)

![ç¤ºä¾‹](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E7%A4%BA%E4%BE%8B.png)



### 1.2ã€Docker ç‰ˆæœ¬ï¼ˆä¸å¯è¢«AnythingLLM/open webUIè°ƒç”¨ï¼‰

å‚è€ƒï¼š 
https://docs.searxng.org/admin/installation-docker.html#installation-docker

```sh
sudo usermod -a -G docker $USER

$ mkdir my-instance
$ cd my-instance
$ export PORT=8080
$ docker pull searxng/searxng
$ docker run --rm \
             -d -p ${PORT}:8080 \
             -v "${PWD}/searxng:/etc/searxng" \
             -e "BASE_URL=http://localhost:$PORT/" \
             -e "INSTANCE_NAME=my-instance" \
             searxng/searxng
2f998.... # container's ID
# --rm é€‰é¡¹çš„æ„æ€æ˜¯â€œåœ¨å®¹å™¨é€€å‡ºåè‡ªåŠ¨åˆ é™¤è¯¥å®¹å™¨â€ã€‚è¿™æ„å‘³ç€ä¸€æ—¦å®¹å™¨åœæ­¢è¿è¡Œï¼ŒDocker ä¼šè‡ªåŠ¨æ¸…ç†å®¹å™¨åŠå…¶æ–‡ä»¶ç³»ç»Ÿï¼Œè¿™æ ·å¯ä»¥é˜²æ­¢ç³»ç»Ÿä¸­æ®‹ç•™å¾ˆå¤šå·²åœæ­¢çš„å®¹å™¨ï¼Œä»è€ŒèŠ‚çœå­˜å‚¨ç©ºé—´å’Œç®€åŒ–ç®¡ç† 

# ç¯å¢ƒå˜é‡UWSGI_WORKERSå’ŒUWSGI_THREADSå°†è¦†ç›–åœ¨/etc/searxng/uwsgi. iniä¸­æŒ‡å®šçš„UWSGIè¿›ç¨‹å’ŒUWSGIçº¿ç¨‹çš„é»˜è®¤æ•°é‡ã€‚ï¼ˆå¯ä»¥ä¸ä¿®æ”¹ï¼Œä¹Ÿå¯ä»¥æ ¹æ®æƒ…å†µæ”¹ï¼‰

$ docker container ls
CONTAINER ID   IMAGE             COMMAND                  CREATED         ...
2f998d725993   searxng/searxng   "/sbin/tini -- /usr/â€¦"   7 minutes ago   ...

# ä¿®æ”¹ setting.yml æ–‡ä»¶ï¼Œ1.format ä¸­åŠ  json æ ¼å¼ï¼›2.æ‰“å¼€ bing ã€sogou ç­‰æµè§ˆå™¨ disable falseï¼›ç„¶åé‡å¯ã€‚
$ docker container restart 2f998

xdg-open "http://localhost:$PORT"


$ docker container stop 2f998
$ docker container rm 2f998
```





# ä¸‰ã€åå‘ä»£ç†

## 1ã€å®‰è£…Nginx Proxy Manager

å®˜æ–¹æ–‡æ¡£ï¼š    https://nginxproxymanager.com/guide/ 

```sh
vim docker-compose.yml

version: '3.8'
services:
  app:
    image: 'jc21/nginx-proxy-manager:latest'
    restart: unless-stopped
    ports:
      - '80:80'
      - '81:81'
      - '443:443'
    volumes:
      - ./data:/data
      - ./letsencrypt:/etc/letsencrypt

```

> version: '3.8'
> æŒ‡å®šäº† Compose æ–‡ä»¶çš„ç‰ˆæœ¬ã€‚è¿™é‡Œä½¿ç”¨çš„æ˜¯ 3.8 ç‰ˆï¼Œè¿™ä¸ªç‰ˆæœ¬æ”¯æŒçš„ä¸€äº›ç‰¹æ€§å’Œè¯­æ³•åœ¨ Docker Compose v2.33.0 ä¸­æ˜¯å…¼å®¹çš„ã€‚
>
> services:
> å®šä¹‰äº†å°†è¦è¿è¡Œçš„å®¹å™¨æœåŠ¡ã€‚æ¯ä¸ªæœåŠ¡éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„å®¹å™¨ã€‚
>
> app:
> è¿™æ˜¯æœåŠ¡çš„åå­—ï¼Œå¯ä»¥éšæ„å®šä¹‰ã€‚è¿™é‡Œç”¨ â€œappâ€ æ¥è¡¨ç¤ºè¿è¡Œ Nginx Proxy Manager çš„å®¹å™¨ã€‚
>
> image: 'jc21/nginx-proxy-manager:latest'
> æŒ‡å®šäº†è¯¥æœåŠ¡ä½¿ç”¨çš„ Docker é•œåƒã€‚
>
> jc21/nginx-proxy-manager æ˜¯é•œåƒåç§°ï¼Œ:latest è¡¨ç¤ºä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„é•œåƒã€‚Docker ä¼šè‡ªåŠ¨ä»ä»“åº“ä¸­æ‹‰å–è¯¥é•œåƒï¼ˆå¦‚æœæœ¬åœ°ä¸å­˜åœ¨çš„è¯ï¼‰ã€‚
> restart: unless-stopped
> å®šä¹‰äº†å®¹å™¨çš„é‡å¯ç­–ç•¥ã€‚
>
> å½“å®¹å™¨å¼‚å¸¸é€€å‡ºæ—¶ä¼šè‡ªåŠ¨é‡å¯ï¼Œé™¤éç”¨æˆ·ä¸»åŠ¨åœæ­¢å®¹å™¨ã€‚
> ports:
> ç”¨äºå°†å®¹å™¨å†…éƒ¨çš„ç«¯å£æ˜ å°„åˆ°ä¸»æœºçš„ç«¯å£ï¼Œä½¿å¤–éƒ¨å¯ä»¥é€šè¿‡ä¸»æœºè®¿é—®å®¹å™¨ä¸­çš„æœåŠ¡ã€‚
>
> '80:80' è¡¨ç¤ºå°†ä¸»æœºçš„ 80 ç«¯å£æ˜ å°„åˆ°å®¹å™¨çš„ 80 ç«¯å£ã€‚
> '81:81' è¡¨ç¤ºå°†ä¸»æœºçš„ 81 ç«¯å£æ˜ å°„åˆ°å®¹å™¨çš„ 81 ç«¯å£ã€‚
> '443:443' è¡¨ç¤ºå°†ä¸»æœºçš„ 443 ç«¯å£æ˜ å°„åˆ°å®¹å™¨çš„ 443 ç«¯å£ã€‚
> volumes:
> ç”¨äºå°†ä¸»æœºä¸Šçš„ç›®å½•æŒ‚è½½åˆ°å®¹å™¨ä¸­ï¼Œè¿™æ ·å¯ä»¥æŒä¹…åŒ–æ•°æ®å’Œé…ç½®æ–‡ä»¶ã€‚
>
> ./data:/data å°†å½“å‰ç›®å½•ä¸‹çš„ data æ–‡ä»¶å¤¹æŒ‚è½½åˆ°å®¹å™¨å†…çš„ /data ç›®å½•ã€‚
> ./letsencrypt:/etc/letsencrypt å°†å½“å‰ç›®å½•ä¸‹çš„ letsencrypt æ–‡ä»¶å¤¹æŒ‚è½½åˆ°å®¹å™¨å†…çš„ /etc/letsencrypt ç›®å½•ï¼Œç”¨äºå­˜å‚¨ SSL è¯ä¹¦ç­‰æ•°æ®ã€‚

```sh
# æŒ‰ç…§ yml ç»™dockeré…ç½®ã€‚
docker compose up -d  

# ç‹¬ç«‹å®‰è£…åˆ™ç”¨ docker-compose up -d
```

## 2ã€npmçš„Webç®¡ç†æ§åˆ¶å°

ä¸€æ—¦å®¹å™¨å¯åŠ¨ï¼Œä½ å¯ä»¥é€šè¿‡æµè§ˆå™¨è®¿é—®Nginx Proxy Managerçš„Webç•Œé¢ã€‚é»˜è®¤åœ°å€æ˜¯`http://<your-server-ip>:81`ã€‚

```sh
# åˆå§‹å¯†ç ï¼š
Email: admin@example.com
Password: changeme

# å…ˆåšä¸€ä¸ª DNS è§£æï¼Œå±€åŸŸç½‘çš„DNS å°±åœ¨å±€åŸŸç½‘è®¿é—®ï¼Œå…¬ç½‘çš„DNSå°±åœ¨å…¬ç½‘è®¿é—®ã€‚ä¸‹é¢ä»£ç†ä¸­ä¼šç”¨åˆ°DNSè§£æçš„åŸŸåDomain Namesã€‚

# Nginx Proxy Manager ä¸­è®¾ç½®æ‚¨è‡ªå·±çš„åŸŸå
# æ·»åŠ ä¸€ä¸ªä»£ç† add proxy host
# ä¸‹é¢çš„æˆªå›¾å°±æ˜¯ä¾‹å­ï¼Œä»¥åç‚¹å‡» http://[åŸŸå] å°±ç›¸å½“äº http://IP:portã€‚  æˆ‘è¿™é‡Œå’©æœ‰æ·»åŠ sslï¼Œä¸èƒ½httpsè®¿é—®ã€‚
```

![å¾®ä¿¡å›¾ç‰‡_20250304153451](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250304153451.png)

![å¾®ä¿¡å›¾ç‰‡_20250308112806](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250308112806.png)

![å¾®ä¿¡å›¾ç‰‡_20250304153445](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250304153445.png)

å¯ä»¥æµ‹è¯•ä¸€ä¸‹ ï¼Œåœ¨å±€åŸŸç½‘æˆ–è€…å…¬ç½‘ä¸­èƒ½ä¸èƒ½ç”¨ åŸŸåè®¿é—®äº†ã€‚

å¯èƒ½éœ€è¦ç­‰å¾…ä¸€ä¸‹æ‰èƒ½ç”Ÿæ•ˆã€‚



> è¡¥å……ï¼šå…è´¹åŸŸåæ³¨å†Œ å’Œ Cloudflare åŸŸåè§£æ
>
> å‚è€ƒï¼š https://blog.csdn.net/u010522887/article/details/140786338
>           https://www.freedidi.com/17434.html
> å¦‚æœå·²ç»æœ‰äº†æœ¬åœ°çš„ DNS è§£æ ä¹Ÿå°±ä¸ç”¨äº†ï¼Œå±€åŸŸç½‘çš„DNSè§£æå±€åŸŸç½‘ç”¨ï¼Œå…¬ç½‘çš„DNSè§£æå…¬ç½‘ç”¨ã€‚

 







# å››ã€æ€è·¯ä¸€ï¼šOllamaéƒ¨ç½²Deepseek

## 1ã€å®‰è£…ollama

```sh
curl -fsSL https://ollama.com/install.sh | sh

# æˆ‘æƒ³è¦æŒ‡å®šollamaä¸‹è½½æ¨¡å‹çš„å­˜æ”¾ä½ç½®åˆ°ç³»ç»Ÿç›˜ï¼Œå› ä¸ºæ•°æ®ç›˜æœ‰80Tï¼Œç³»ç»Ÿåªæœ‰500Gã€‚
sudo chown -R ollama:ollama /home/cys/data/models

# ä¿®æ”¹ollamaæœåŠ¡é…ç½®ï¼ŒåŠ å‡ ä¸ªç¯å¢ƒå‚æ•°Environmentï¼Œå®ç°è®¿é—®æŒ‡å®šæ–‡ä»¶å¤¹ã€å¤–æœºè®¿é—®.
# ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œä¸ºäº†å®‰å…¨èµ·è§ï¼Œå»ºè®®å°† OLLAMA_ORIGINS è®¾ç½®ä¸ºç‰¹å®šçš„åŸŸåæˆ– IP åœ°å€ï¼Œä»¥é™åˆ¶åªæœ‰æˆæƒçš„æ¥æºæ‰èƒ½è®¿é—®æœåŠ¡.
sudo vim /etc/systemd/system/ollama.service
--------------------------------------------------------------------------
[Unit]
Description=Ollama Service
After=network-online.target

[Service]
ExecStart=/usr/local/bin/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3
Environment="PATH=/home/cys/.local/bin:/home/cys/.local/bin:/home/cys/miniconda3/bin:/home/cys/miniconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin"
Environment="OLLAMA_MODELS=/home/cys/data/models"
Environment="OLLAMA_HOST=0.0.0.0:11434"
Environment="OLLAMA_ORIGINS=*"

[Install]
WantedBy=default.target
--------------------------------------------------------------------------

sudo systemctl daemon-reload
sudo systemctl enable ollama
sudo systemctl start ollama
sudo systemctl status ollama

ollama pull deepseek-r1:1.5b
ollama list
# æŸ¥çœ‹æŒ‡å®šæ–‡ä»¶å¤¹ä¸­æ˜¯å¦æœ‰äº†ä¸‹è½½çš„æ–°æ¨¡å‹
ll /home/cys/data/models/blobs/

ollama run deepseek-r1:70b

```



## 2.1ã€æ–¹æ¡ˆä¸€ï¼šï¼ˆollama+anythingllm+searxng+Nignx proxy managerï¼‰

ç”¨ollamaåœ¨æœ¬åœ°éƒ¨ç½² deepseek-r1-70bæ¨¡å‹ï¼Œç„¶åå®‰è£…dockerï¼Œåœ¨docker ä¸­æ–¹ä¾¿çš„ä¸‹è½½é•œåƒ AnythingLLMï¼Œå®¹å™¨åŒ–AnythingLLMå®ç°RAGã€‚

### 2.1.1ã€Dockerä¸‹å®‰è£…AnythingLLM

```sh
# docker pull mintplexlabs/anythingllm
# ä¸‹é¢è¿™æ ·ä¸å¥½ï¼Œè¿˜æ˜¯è¦åƒå®˜ç½‘ä¸€æ ·æŒ‡å®šå®¹å™¨åˆ°å®¿ä¸»æœºçš„æ˜ å°„å¥½ï¼Œè¿™æ ·æ›´æ–°äº†å®¹å™¨é•œåƒå•¥çš„ï¼Œæ•°æ®å¯ä»¥ä»æœ¬åœ°ç»§æ‰¿ã€‚
# docker run -d -p 3001:3001 --name AnythingLLM mintplexlabs/anythingllm
docker pull mintplexlabs/anythingllm:latest

docker stop AnythingLLM && docker rm AnythingLLM  # æ¸…ç†æ—§å®¹å™¨
export STORAGE_LOCATION=/home/cys/docker_data/anythingllm  # ç¡®ä¿ä¸åŸè·¯å¾„ä¸€è‡´


mkdir -p $STORAGE_LOCATION
cd ${STORAGE_LOCATION}
touch .env

docker run -d -p 3001:3001 \
  --name AnythingLLM \
  --network host \
  --cap-add SYS_ADMIN \
  -v ${STORAGE_LOCATION}:/app/server/storage \
  -v ${STORAGE_LOCATION}/.env:/app/server/.env \
  -e STORAGE_DIR="/app/server/storage" \
  mintplexlabs/anythingllm


# å¤–éƒ¨ç”¨3001ç«¯å£è®¿é—®dockerå®¹å™¨å†…éƒ¨çš„3001ç«¯å£ï¼Œ# å¤–éƒ¨ç”¨3002ç«¯å£è®¿é—®dockerå®¹å™¨å†…éƒ¨çš„3001ç«¯å£
# åŒä¸€ä¸ªé•œåƒåšæˆäº†ä¸¤ä¸ªä¸åŒçš„å®¹å™¨ï¼Œå¤–éƒ¨ç”¨ä¸åŒçš„ç«¯å£è®¿é—®ã€‚å®é™…éƒ¨ç½²è®°å¾—åˆ†é…å¥½cpuå†…å­˜ç­‰èµ„æºï¼Œæ€•ä¸¤ä¸ªå®¹å™¨æ‰“æ¶æŠ¢ã€‚
# docker run -d -p 3001:3001 --name AnythingLLM mintplexlabs/anythingllm
# docker run -d -p 3002:3001 --name AnythingLLM2 mintplexlabs/anythingllm

# æ£€æŸ¥å®¹å™¨è¿è¡Œ
docker ps | grep AnythingLLM  # åº”æ˜¾ç¤ºUpçŠ¶æ€

docker start AnythingLLM
docker stop AnythingLLM

# 
```

### 2.1.2ã€AnythingLLMæ§åˆ¶ç•Œé¢é…ç½®

åœ¨å¤–éƒ¨æœºå™¨ï¼Œæ¯”å¦‚ä¸€å°Windowsæœºå™¨ï¼Œæµè§ˆå™¨è®¿é—® Ubuntuæœºå™¨çš„ IP:3001ã€‚

è¿›å…¥ä¸€æ­¥ä¸€æ­¥è®¾ç½®ï¼Œæ¨è é€‰å›¢é˜Ÿä½¿ç”¨ï¼Œå¯ä»¥æ·»åŠ ä½¿ç”¨æˆå‘˜ã€‚

![å¾®ä¿¡å›¾ç‰‡_20250228154513](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228154513.png)

![å¾®ä¿¡å›¾ç‰‡_20250228154507](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228154507.png)

![å¾®ä¿¡å›¾ç‰‡_20250228154516](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228154516.png)

![æˆªå±2025-02-28 15.39.57](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-02-28%2015.39.57.jpg)

ç‚¹å‡»è¿™ä¸€ä¸ªworkspaceä¸­çš„ ä¸Šä¼  æ–‡ä»¶å¯ä»¥å®ç° RAGã€‚

![å¾®ä¿¡å›¾ç‰‡_20250228154522](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228154522.png)

ç‚¹å‡»è¿™ä¸€ä¸ªworkspaceä¸­çš„è®¾ç½®æŒ‰é’®ï¼Œåœ¨èŠå¤©è®¾ç½®å¯ä»¥æŠŠ è¿™ä¸ªworkspaceé€‰æ‹© chatæ¨¡å¼æˆ–è€…æŸ¥è¯¢æ¨¡å¼ï¼ŒæŸ¥è¯¢æ¨¡å¼ä¼˜å…ˆä»çŸ¥è¯†åº“ä¸­æ‰¾å†…å®¹å›ç­”ï¼Œchat åˆ™ä¼˜å…ˆä½¿ç”¨ è‡ªå·±è®­ç»ƒçš„æ¨¡å‹ä¸ºä¸»ï¼Œä½†æ˜¯ä¹Ÿä¼šå‚è€ƒçŸ¥è¯†åº“ã€‚

ç‚¹å‡»ä¸‹æ–¹ æ‰³æ‰‹ğŸ”§ï¼Œå¯ä»¥è¿›å…¥agentä»£ç†æ‰“å¼€è”ç½‘æœç´¢åŠŸèƒ½ï¼Œä½†æ˜¯æ³¨æ„æœ‰çš„æ˜¯å›½å†…ç”¨ä¸äº†çš„ï¼Œæœ‰çš„è¦æ”¶è´¹ï¼Œæ¨èä½¿ç”¨å¼€æºçš„æœ¬åœ°éƒ¨ç½²çš„æœç´¢å¼•æ“ã€‚

![å¾®ä¿¡å›¾ç‰‡_20250228154527](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228154527.png)

toræµè§ˆå™¨çš„DuckDuckGo æµè§ˆå™¨åœ¨å›½å†…å°±ä¸æ–¹ä¾¿ç”¨ã€‚



## 2.1ã€æ–¹æ¡ˆäºŒï¼šï¼ˆollama+open web UI+searxng+Nignx proxy managerï¼‰

å‰æä¹Ÿæ˜¯åœ¨å®‰è£…å¥½ollama çš„åŸºç¡€ä¸Šè¿›è¡Œçš„ã€‚
å‚è€ƒï¼š
https://github.com/open-webui/open-webui
https://www.composerize.com/   
https://www.bilibili.com/video/BV1MS9BYaEa5/?spm_id_from=333.337.search-card.all.click&vd_source=a07523372ea1438247b770c295f20822



å…ˆå®‰è£…    ã€NVIDIA Container Toolkit NVIDIAå®¹å™¨å·¥å…·åŒ…ã€‘
å‚è€ƒï¼š https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html

```sh
mkdir -p openwebui
cd openwebui 

# æ¨èè¿˜æ˜¯ç”¨docker æ–¹ä¾¿ç®¡ç†ï¼Œåœ¨open webUI å®˜ç½‘çš„GitHub æ‰¾åˆ° æœ¬åœ°æœ‰ollama çš„å®‰è£…å‘½ä»¤ï¼Œç„¶åç”¨composerizeç½‘ç«™æŠŠè¿™ä¸ªå‘½ä»¤è½¬æˆ docker-compose.yml çš„æ ¼å¼ï¼Œæ–¹ä¾¿ç®¡ç†ã€‚
# docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda

# æ–°å»ºä¸€ä¸ª docker-compose.yml çš„æ ¼å¼ æ–‡ä»¶ï¼ŒæŠŠåˆšæ‰çš„ å†…å®¹è´´ä¸Šå»(è§ä¸‹æ–¹æˆªå›¾)ã€‚
vim docker-compose.yml

# æ ¹æ®è¿™ä¸ª docker-compose.yml  å†…å®¹æ‹‰å–
docker compose pull 

# é‡æ–°æ„å»ºå¹¶å¯åŠ¨å®¹å™¨
docker compose up -d 
# å¦‚æœæç¤ºæ²¡æœ‰ volume å°±å»ºç«‹ä¸€ä¸ª 
# docker volume create open-webui
# docker restart open-webui
# è¿™ä¸€æ­¥éœ€è¦ç­‰å¾…2åˆ†é’Ÿï¼Œå¦‚æœç½‘ç»œè®¿é—®ä¸åˆ° openaiå®˜ç½‘çš„è¯ã€‚å¯å‚è€ƒä¸‹æ–¹è¡¥å……å†…å®¹ã€Šopen webUIç™½å±é—®é¢˜è§£å†³ã€‹

# æ£€æŸ¥å®¹å™¨å†… æ—¥å¿— 100è¡Œã€‚(çœ‹çœ‹æœ‰æ²¡æœ‰å¯åŠ¨ï¼Œç„¶åç”¨æµè§ˆå™¨è¿›å…¥3000ç«¯å£æ£€æŸ¥ä¸€ä¸‹)
docker compose logs -f --tail=100
```

docker-compose.ymlæˆªå›¾
![æˆªå±2025-03-09 17.43.47](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-09%2017.43.47.jpg)

```yaml
name: <your project name>
services:
    open-webui:
        ports:
            - 3000:8080
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: all
                          capabilities:
                              - gpu
        extra_hosts:
            - host.docker.internal:host-gateway
        volumes:
            - open-webui:/app/backend/data
        container_name: open-webui
        restart: always
        image: ghcr.io/open-webui/open-webui:cuda
volumes:
    open-webui:
        external: true
        name: open-webui
```

![å¾®ä¿¡å›¾ç‰‡_20250309131910](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250309131910.png)

![å¾®ä¿¡å›¾ç‰‡_20250309131717](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250309131717.png)

 ![dl](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/dl.png)

### 2.1.1ã€è”ç½‘æœç´¢éƒ¨ç½²æˆåŠŸæ¡ˆä¾‹

å‚è€ƒï¼š

â€‹       https://mp.weixin.qq.com/s/Fgwn9DYit65sw7ql1S3Pfw

#### 2.1.1.1ã€é…ç½®searxng

```sh
mkdir -p /home/cys/docker_data/searxng/searxng
cd /home/cys/docker_data/searxng/searxng

vim settings.yml
# ---------------------------- settings.yml --------------------------------
use_default_settings: true

general:
  debug: true

engines:
  # å¯ç”¨é»˜è®¤ç¦ç”¨çš„å¼•æ“
  #  - name: bing
  #  disabled: false
  #  delay: 5  # æ¯æ¬¡è¯·æ±‚é—´éš”5ç§’
  #  enable_http: true    # å…è®¸ HTTP åè®®
  #  request_timeout: 30  # å»¶é•¿è¶…æ—¶è‡³ 30 ç§’ï¼ˆç½‘é¡µ5å»ºè®®45-60ç§’ï¼‰
  #  url: https://cn.bing.com/search?q={query}  # å¼ºåˆ¶ä½¿ç”¨å›½å†…ç‰ˆ 

#  - name: bing
#   disabled: false
  - name: bing
    engine: bing
    shortcut: bi
    disabled: false
#    request_timeout: 30

  - name: bilibili
    engine: bilibili
    shortcut: bil
    disabled: false

  # ç¦ç”¨é»˜è®¤å¯ç”¨çš„å¼•æ“
  - name: archlinuxwiki
    engine: archlinux
    disabled: true
  - name: duckduckgo
    engine: duckduckgo
    distabled: true
  - name: github
    engine: github
    shortcut: gh
    disabled: true
  - name: wikipedia
    engine: wikipedia
    disabled: true

server:
  # base_url is defined in the SEARXNG_BASE_URL environment variable, see .env and docker-compose.yml
  secret_key: "ultrasecretkkkkey"  # change this! è¿™é‡Œä¸€å®šè¦ä¿®æ”¹!!!!!!!!!
  limiter: false  # can be disabled for a private instance
  image_proxy: true

search:
  formats:
    - html
    - json  # å…è®¸ä»¥ json å½¢å¼è¿”å›ç»“æœ

ui:
  static_use_hash: true

redis:
  url: redis://redis:6379/0
# ------------------------------ settings.yml ------------------------------

vim limiter.toml # è¯¥æ–‡ä»¶ç”¨äºè®¿é—®é™åˆ¶ï¼ˆåçˆ¬è™«ï¼‰ã€‚
# ------------------------------ limiter.toml ------------------------------
# See https://github.com/searxng/searxng/blob/master/searx/limiter.toml
[botdetection.ip_limit]
# activate link_token method in the ip_limit method
link_token = false
# ------------------------------ limiter.toml ------------------------------

cd /home/cys/docker_data/searxng/
vim docker-compose.yml
# ------------------------------ docker-compose.yml ------------------------------

services:
  redis:
    container_name: redis
    image: hub.mirrorify.net/valkey/valkey:8-alpine
    command: valkey-server --save 301 --loglevel warning
    restart: unless-stopped
    networks:
      - searxng
    volumes:
      - valkey-data2:/data
    cap_drop:
      - ALL
    cap_add:
      - SETGID
      - SETUID
      - DAC_OVERRIDE
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"

  searxng:
    container_name: searxng
    image: searxng/searxng:latest
    restart: unless-stopped
    networks:
      - searxng
    ports:
      # è¿™é‡Œè®¾ç½® 8081 ç«¯å£
      - 8081:8080
    volumes:
      - ./searxng:/etc/searxng:rw
    environment:
      - SEARXNG_BASE_URL=http://10.5.9.252:8081 # https://${SEARXNG_HOSTNAME:-localhost}/
      - UWSGI_WORKERS=${SEARXNG_UWSGI_WORKERS:-4}
      - UWSGI_THREADS=${SEARXNG_UWSGI_THREADS:-4}
    # å°†å®¹å™¨çš„æ‰€æœ‰ Linux capabilities å»é™¤ï¼Œç¡®ä¿å®‰å…¨æ€§ã€‚ å†åŠ å…¥ä¸€äº›å®¹å™¨æƒé™
    cap_drop:    
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    logging:    
      driver: "json-file" # ä½¿ç”¨ JSON æ–‡ä»¶æ ¼å¼ä¿å­˜æ—¥å¿—
      options:
        max-size: "1m"    # æ¯ä¸ªæ—¥å¿—æ–‡ä»¶æœ€å¤§ 1 MB
        max-file: "1"     # æœ€å¤šä¿ç•™ 1 ä¸ªæ—¥å¿—æ–‡ä»¶ï¼Œé˜²æ­¢æ—¥å¿—æ— é™å¢é•¿å¯¼è‡´ç£ç›˜å æ»¡ã€‚

networks:
  searxng:

volumes:
  valkey-data2:
# ------------------------------ docker-compose.yml ------------------------------

# å…ˆåœæ­¢å·²å¯åŠ¨çš„æœåŠ¡
docker compose down
# å¯åŠ¨æœåŠ¡ - åå°å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼
sudo docker compose up -d
# å¯åŠ¨æœåŠ¡ - å‰å°æ¨¡å¼ï¼Œå½“é‡åˆ°é—®é¢˜éœ€è¦ç»“åˆæ—¥å¿—å³æ—¶åˆ†ææ—¶ï¼Œå¯ç”¨è¿™ç§æ¨¡å¼å¯åŠ¨
sudo docker compose up 
```

> redis æœåŠ¡ä¸­çš„ volumesï¼Œsearxng æœåŠ¡ä¸­çš„ volumesï¼Œä»¥searxngä¸ºä¾‹ã€‚
> **ä½œç”¨ï¼š** å°†å®¿ä¸»æœºå½“å‰ç›®å½•ä¸‹çš„ `./searxng` æ–‡ä»¶å¤¹æŒ‚è½½åˆ° searxng å®¹å™¨å†…éƒ¨çš„ `/etc/searxng` ç›®å½•ï¼Œå¹¶ä»¥è¯»å†™æ¨¡å¼ï¼ˆrwï¼‰æŒ‚è½½ã€‚**æ„ä¹‰ï¼š** è¿™æ ·å¯ä»¥ç›´æ¥åœ¨å®¿ä¸»æœºä¸Šç¼–è¾‘ searxng çš„é…ç½®æ–‡ä»¶ï¼ˆæ¯”å¦‚ `settings.yml` ç­‰ï¼‰ï¼Œå®¹å™¨å†…ä¼šè‡ªåŠ¨åŒæ­¥æ›´æ–°ï¼Œä»è€Œæ–¹ä¾¿ç®¡ç†å’Œè°ƒè¯•ã€‚
>
> æœ€åº•éƒ¨çš„ volumes éƒ¨åˆ†
>
> **ä½œç”¨ï¼š** åœ¨ Compose æ–‡ä»¶çš„é¡¶å±‚å£°æ˜ä¸€ä¸ªåä¸º `valkey-data2` çš„å‘½åå·ã€‚**æ„ä¹‰ï¼š** è¿™å‘Šè¯‰ Docker Composeï¼Œè¿™ä¸ªå·ç”± Docker ç®¡ç†ï¼Œç”¨äºæŒä¹…åŒ–å­˜å‚¨ã€‚æœåŠ¡ï¼ˆæ¯”å¦‚ redisï¼‰åœ¨ä½¿ç”¨æŒ‚è½½æ—¶ä¼šè‡ªåŠ¨å…³è”åˆ°è¿™ä¸ªå·²å£°æ˜çš„å·ã€‚
> è¿™è¡Œé…ç½®åªæ˜¯å£°æ˜äº†ä¸€ä¸ªåå­—å« `valkey-data2` çš„å·ï¼ŒDocker ä¼šè‡ªåŠ¨ä¸ºå®ƒåˆ†é…ä¸€ä¸ªé»˜è®¤çš„å­˜å‚¨ä½ç½®ï¼ˆåœ¨ Linux ä¸Šé€šå¸¸æ˜¯ `/var/lib/docker/volumes/valkey-data2/_data` ä¹Ÿå¯èƒ½æœ‰æœåŠ¡ä½œä¸ºå‰ç¼€ï¼‰ã€‚
>
> å®¹å™¨å†…çš„æ˜ å°„ä½ç½®ä¸æ˜¯åœ¨è¿™é‡ŒæŒ‡å®šçš„ï¼Œè€Œæ˜¯åœ¨å„ä¸ªæœåŠ¡çš„ `volumes` æŒ‚è½½æ—¶ç¡®å®šçš„ã€‚

æµè§ˆå™¨ä¸­è®¿é—® http://10.5.9.252 çš„8081ç«¯å£å³å¯è®¿é—®ç½‘é¡µç‰ˆæœ¬çš„searxngã€‚

#### 2.1.1.2ã€å®‰è£…é…ç½® open webUI

```sh
# æ‹‰å–åµŒå…¥æ¨¡å‹
ollama pull bge-m3

mkdir -p /home/cys/docker_data/openwebui2
cd /home/cys/docker_data/openwebui2

vim docker-compose.yml
# ------------------------------ docker-compose.yml ------------------------------
services:
  open-webui:
    # image: ghcr.io/open-webui/open-webui:main
    image: ghcr.io/open-webui/open-webui:cuda
    #image: ghcr.mirrorify.net/open-webui/open-webui:main
    environment:
      # æ—¥å¿—å…¨å±€ä¸ºå…¨å±€ DEBUG æ¨¡å¼ï¼Œå¯ä»¥æ‰“å°æ›´å¤šçš„ä¿¡æ¯ã€‚åœ¨éœ€åˆ†æé—®é¢˜æ—¶å¯é…ç½®ï¼Œå…¶ä»–æ—¶é—´å¯æ³¨é‡Š
      - GLOBAL_LOG_LEVEL=DEBUG
      # ollama è®¿é—®åœ°å€ã€‚è¯·ç¡®ä¿å·²å®‰è£…äº† ollama
      - OLLAMA_API_BASE_URL=http://10.5.9.252:11434
      # è‡ªå®šä¹‰ HF å›½å†…ä»£ç†åœ°å€
      - HF_ENDPOINT=https://hf-mirror.com
      # è‡ªå®šä¹‰ç½‘ç«™åç§°
      # - WEBUI_NAME="OWU"
      # ç¦ç”¨ openAIï¼Œå¦åˆ™ç™»å½•æ—¶ä¼šå› ä¸ºè¯·æ±‚å®ƒè¶…æ—¶è€Œç™½å±
      - ENABLE_OPENAI_API=false
      # å¦‚æœæœ‰ open AI æœåŠ¡çš„ä»£ç†åœ°å€ï¼Œå¯ä»¥é€šè¿‡è¿™é‡ŒæŒ‡å®š
      - OPENAI_API_BASE_URL=https://api.openai.com/v1
      # å…è®¸æ‰€æœ‰æ¥æºçš„ç«™ç‚¹è·¨åŸŸè¯·æ±‚æœåŠ¡ APIã€‚è‹¥æœåŠ¡éƒ¨ç½²åˆ°äº†äº’è”ç½‘è®¿é—®ï¼Œä¸è¦è¿™ä¹ˆé…ç½®
      - CORS_ALLOW_ORIGIN=*
      # æŒ‡å®šé»˜è®¤åµŒå…¥æ¨¡å‹ï¼Œè¯·æ³¨æ„å…ˆæ‹‰å–è¯¥æ¨¡å‹ï¼šollama pull bge-m3
      - RAG_EMBEDDING_MODEL=bge-m3
      # æŒ‡å®šé»˜è®¤ä½¿ç”¨çš„æ¨¡å‹ã€‚è¯·å…ˆæ‹‰å–è¯¥æ¨¡å‹ï¼šollama pull deepseek-r1:8b
      - DEFAULT_MODELS=deepseek-r1:70b
      # å…è®¸æ–°ç”¨æˆ·æ³¨å†Œ
      - ENABLE_OAUTH_SIGNUP=true
    ports:
      - 8080:8080
    volumes:
      - ./open_webui_data:/app/backend/data
# ------------------------------ docker-compose.yml ------------------------------

# å…ˆåœæ­¢å·²å¯åŠ¨çš„æœåŠ¡
docker compose down
# å¯åŠ¨æœåŠ¡ - åå°å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼
sudo docker compose up -d
# å¯åŠ¨æœåŠ¡ - å‰å°æ¨¡å¼ï¼Œå½“é‡åˆ°é—®é¢˜éœ€è¦ç»“åˆæ—¥å¿—å³æ—¶åˆ†ææ—¶ï¼Œå¯ç”¨è¿™ç§æ¨¡å¼å¯åŠ¨
sudo docker compose up 
```

#### 2.1.1.3ã€ç½‘é¡µä¸­é…ç½®

![å¾®ä¿¡å›¾ç‰‡_20250311095926](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250311095926.png)

![å¾®ä¿¡å›¾ç‰‡_20250311095931](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250311095931.png)

![å¾®ä¿¡å›¾ç‰‡_20250311095937](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250311095937.png)

åœ¨é…ç½®ã€Searxng æŸ¥è¯¢ URLã€‘

```sh
http://10.5.9.252:8081/search?time_range=&categories=general&language=auto&locale=zh-Hans-CN&image_proxy=1&safesearch=0&theme=simple&disabled_engines=currency__general,wikidata__general,duckduckgo__general,google__general,lingva__general,qwant__general&enabled_engines=bing__general,brave__general
```

> å¯æŸ¥çœ‹å¦‚ä¸‹åœ°å€ä¸­ Open-WebUI æ¥å…¥ SearXNG çš„å®ç°æºç äº†è§£å…¶å…·ä½“é€»è¾‘ï¼š
>
> > https://github.com/open-webui/open-webui/blob/main/backend/open_webui/retrieval/web/searxng.py

![å¾®ä¿¡å›¾ç‰‡_20250311095941](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250311095941.png)

æ•ˆæœå›¾å¦‚ä¸‹ï¼š

![å¾®ä¿¡å›¾ç‰‡_20250311095945](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250311095945-1658497.png)

![å¾®ä¿¡å›¾ç‰‡_20250311095807](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250311095807.png)

æ•ˆæœå¹¶ä¸å¥½ï¼Œç»å¸¸ä¼šå‡ºç°æœä¸åˆ°çš„æƒ…å†µã€‚



### 2.1.2ã€è¡¥å……è¯´æ˜éƒ¨åˆ†

#### 2.1.2.1ã€æœ¬åœ°æ•°æ®æ˜ å°„ã€è¿ç§»

```yaml
services:
  redis:
    volumes:
      - valkey-data2:/data
    
  searxng:
    volumes:
      - ./searxng:/etc/searxng:rw

networks:
  searxng:
volumes:
  valkey-data2:
```

> ä»¥å‰é¢é…ç½® searxng ä¸ºä¾‹
> redis æœåŠ¡ä¸­çš„ volumesæ˜ å°„ ä»¥åŠsearxng æœåŠ¡ä¸­çš„ volumes æ˜ å°„ï¼Œä»¥searxngä¸ºä¾‹ã€‚
> **ä½œç”¨ï¼š** å°†å®¿ä¸»æœºå½“å‰ç›®å½•ä¸‹çš„ `./searxng` æ–‡ä»¶å¤¹æŒ‚è½½åˆ° searxng å®¹å™¨å†…éƒ¨çš„ `/etc/searxng` ç›®å½•ï¼Œå¹¶ä»¥è¯»å†™æ¨¡å¼ï¼ˆrwï¼‰æŒ‚è½½ã€‚**æ„ä¹‰ï¼š** è¿™æ ·å¯ä»¥ç›´æ¥åœ¨å®¿ä¸»æœºä¸Šç¼–è¾‘ searxng çš„é…ç½®æ–‡ä»¶ï¼ˆæ¯”å¦‚ `settings.yml` ç­‰ï¼‰ï¼Œå®¹å™¨å†…ä¼šè‡ªåŠ¨åŒæ­¥æ›´æ–°ï¼Œä»è€Œæ–¹ä¾¿ç®¡ç†å’Œè°ƒè¯•ã€‚
>
> æœ€åº•éƒ¨çš„ volumes éƒ¨åˆ†
>
> **ä½œç”¨ï¼š** åœ¨ Compose æ–‡ä»¶çš„é¡¶å±‚å£°æ˜ä¸€ä¸ªåä¸º `valkey-data2` çš„å‘½åå·ï¼ˆæ²¡æœ‰æŒ‡å®šæ˜ å°„åˆ°å®¹å™¨ä¸­çš„æŸä¸ªä½ç½®ï¼‰ã€‚**æ„ä¹‰ï¼š** è¿™å‘Šè¯‰ Docker Composeï¼Œè¿™ä¸ªå·ç”± Docker ç®¡ç†ï¼Œç”¨äºæŒä¹…åŒ–å­˜å‚¨ã€‚æœåŠ¡ï¼ˆæ¯”å¦‚ redisï¼‰åœ¨ä½¿ç”¨æŒ‚è½½æ—¶ä¼šè‡ªåŠ¨å…³è”åˆ°è¿™ä¸ªå·²å£°æ˜çš„å·ã€‚
> è¿™è¡Œé…ç½®åªæ˜¯å£°æ˜äº†ä¸€ä¸ªåå­—å« `valkey-data2` çš„å·ï¼ŒDocker ä¼šè‡ªåŠ¨ä¸ºå®ƒåˆ†é…ä¸€ä¸ªé»˜è®¤çš„å­˜å‚¨ä½ç½®ï¼ˆåœ¨ Linux ä¸Šé€šå¸¸æ˜¯ `/var/lib/docker/volumes/valkey-data2/_data` ä¹Ÿå¯èƒ½æœ‰æœåŠ¡ä½œä¸ºå‰ç¼€ï¼‰ã€‚
>
> å®¹å™¨å†…çš„æ˜ å°„ä½ç½®ä¸æ˜¯åœ¨è¿™é‡ŒæŒ‡å®šçš„ï¼Œè€Œæ˜¯åœ¨å„ä¸ªæœåŠ¡çš„ `volumes` æŒ‚è½½æ—¶ç¡®å®šçš„ã€‚

å‘½åå· valkey-data2 æŒ‚è½½åˆ° redis å®¹å™¨å†…çš„ /data ç›®å½•ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œredis åœ¨ /data ä¸‹å†™å…¥çš„æ•°æ®éƒ½ä¼šå­˜å‚¨åˆ°è¿™ä¸ªå‘½åå·ä¸­ã€‚

å¦‚æœæœåŠ¡è¿è¡Œå¾ˆä¹…äº§ç”Ÿå¤§é‡æ•°æ®ï¼Œè¿™äº›æ•°æ®ä¼šå†™å…¥åˆ°å®¹å™¨ä¸­è¢«æ˜ å°„çš„ç›®å½•ï¼ˆæ¯”å¦‚ redis çš„ /dataï¼‰ï¼Œè€Œæœ€ç»ˆå­˜æ”¾åœ¨å®¿ä¸»æœºä¸Šå¯¹åº”å‘½åå·çš„é»˜è®¤ä½ç½®ï¼ˆå¦‚ /var/lib/docker/volumes/valkey-data2/_dataï¼‰ã€‚

å¦‚æœä½ æƒ³è‡ªå®šä¹‰å®¿ä¸»æœºä¸Šçš„å­˜å‚¨ä½ç½®ï¼ˆä¾‹å¦‚æ”¹ä¸º `/data/docker-data/sear`ï¼‰ï¼Œä½ ä¸èƒ½åœ¨é¡¶å±‚çš„ `volumes` å£°æ˜é‡Œç›´æ¥æŒ‡å®šå®¿ä¸»æœºç›®å½•ï¼Œè€Œæ˜¯éœ€è¦åœ¨æœåŠ¡çš„ `volumes` æ˜ å°„ä¸­ä½¿ç”¨ç»‘å®šæŒ‚è½½çš„æ–¹å¼ã€‚ä¾‹å¦‚ï¼Œå¯¹äº searxng æœåŠ¡ï¼Œå¦‚æœåŸæ¥æ˜¯è¿™æ ·å†™ï¼š

```yaml
volumes:
  - ./searxng:/etc/searxng:rw
# ä»¥åŠ
volumes:
  - valkey-data2:/data
```

ä½ å¯ä»¥ä¿®æ”¹ä¸ºï¼š

```yaml
volumes:
  - /data/docker-data/sear:/etc/searxng:rw
# ä»¥åŠ
volumes:
  - /data/docker-data/redis:/data
```

è¿™æ ·ï¼Œå®¹å™¨ä¸­ `/etc/searxng` çš„æ‰€æœ‰æ•°æ®å°±ä¼šç›´æ¥å­˜å‚¨åœ¨å®¿ä¸»æœºçš„ `/data/docker-data/sear` ç›®å½•ä¸­ï¼Œè€Œä¸å†ä½¿ç”¨é»˜è®¤çš„ `./searxng` ç›®å½•ã€‚ï¼ˆéœ€è¦æå‰æœ‰è¿™ä¸ªæ–‡ä»¶å¤¹ä¸”æƒé™æ‰“å¼€ï¼‰
**æ³¨æ„ï¼šradisè¦é¢‘ç¹ IO æ“ä½œï¼Œä¸å»ºè®®ä¿®æ”¹ä½ç½®åˆ°åˆ«çš„ç£ç›˜ã€‚**

æŠŠåŸæ¥çš„ æ–‡ä»¶å¤¹ cp è¿‡å»ï¼Œç„¶å åœ¨æ”¹yaml æ–‡ä»¶ï¼Œé‡æ–° docker compose up -d ï¼Œå¯ä»¥è¿ç§»äº†ï¼Œå¦‚æœè¿˜æ˜¯ä¸æˆåŠŸï¼Œå¯ä»¥åœ¨docker logs ã€å®¹å™¨å/idã€‘ çœ‹çœ‹æ—¥å¿—æç¤ºã€‚

#### 2.1.2.2ã€æ—¥å¿—

æ—¥å¿—æ–‡ä»¶é»˜è®¤å­˜å‚¨åœ¨å®¿ä¸»æœºçš„ `/var/lib/docker/containers/<container-id>/` ç›®å½•ä¸­ã€‚
æ—¥å¿—æ–‡ä»¶ç”± Docker å¼•æ“ç®¡ç†ï¼Œ**ä¸å®¹å™¨å…±å­˜äº¡**ã€‚å½“å®¹å™¨è¢«åˆ é™¤ï¼ˆå¦‚æ‰§è¡Œ `docker compose down`ï¼‰åï¼Œå…¶æ—¥å¿—æ–‡ä»¶ä¹Ÿä¼šè¢«æ¸…ç†ã€‚

å¦‚æœå¸Œæœ›å°†æ—¥å¿—æ–‡ä»¶å­˜å‚¨åœ¨ç‰¹å®šçš„å®¿ä¸»æœºç›®å½•ä¸­ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ Docker çš„ `local` æ—¥å¿—é©±åŠ¨ç¨‹åºï¼Œå¹¶æŒ‡å®š `log-path`ã€‚

è¯·æ³¨æ„ï¼Œç›´æ¥å°† Redis çš„æ—¥å¿—è¾“å‡ºåˆ°æ–‡ä»¶å¯èƒ½ä¼šå½±å“æ€§èƒ½ï¼Œä¸å»ºè®®ã€‚

```yaml
services:
  open-webui:
    # ...ï¼ˆå…¶ä»–é…ç½®ï¼‰
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - ./open_webui_data:/app/backend/data
```



#### 2.1.2.3ã€æ”¹æ¢åµŒå…¥æ¨¡å‹

è§ ç›®å½•ã€Šæ€è·¯äºŒï¼švllméƒ¨ç½²Deepseekã€‹



#### 2.1.2.4ã€RAG

ç‚¹å‡»å·¥ä½œç©ºé—´ï¼›ç‚¹å‡»â€œçŸ¥è¯†åº“â€é€‰é¡¹ï¼›ä¼ å¥½æ–‡ä»¶ï¼›å†ç‚¹å‡»æ¨¡å‹ï¼›åœ¨ç¼–è¾‘ä¸­é€‰æ‹©å…³è”ä¸Šå“ªäº›çŸ¥è¯†åº“å³å¯ã€‚



#### 2.1.2.5ã€è‡ªå»ºsearxngæœç´¢å¼•æ“æ’ä»¶å®ç°å¾®ä¿¡æœç´¢

è¦è¯»æºç è‡ªå·±ä»¿å†™ï¼Œæš‚æ—¶æ²¡å†™ï¼Œéš¾åº¦ä¸å¤§ã€‚


#### 2.1.2.6ã€è®©ç”¨æˆ·èƒ½å¤Ÿè‡ªå·±æ³¨å†Œ

![å¾®ä¿¡å›¾ç‰‡_20250314105527](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250314105527.png)

![å¾®ä¿¡å›¾ç‰‡_20250314105533](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250314105533.png)



# å››ã€æ€è·¯äºŒï¼švllméƒ¨ç½²Deepseek

## 1ã€æ–¹æ¡ˆï¼šï¼ˆvllm+open web UI+searxng+Nignx proxy managerï¼‰

### 1.1ã€modelscopeæœ¬åœ°ä¸‹è½½å¤§æ¨¡å‹

å›½å†…ç”¨modelscopeæœ¬åœ°ä¸‹è½½å¤§æ¨¡å‹ï¼Œä¸ºvllmè°ƒç”¨ä½œé“ºå«ã€‚

https://www.modelscope.cn/models/
**æ³¨æ„**ï¼šå¦‚æœå¤šGPUéœ€ä¸‹è½½ **DeepSeek-R1-70B-AWQ** åˆ†ç‰‡ç‰ˆæ¨¡å‹ï¼ˆæ”¯æŒå¼ é‡å¹¶è¡Œï¼‰ï¼Œä»¥ä¸‹åªæ˜¯æ¼”ç¤ºæ²¡æœ‰é€‰AWQç‰ˆæœ¬ã€‚
å‡å¦‚ä¸‹è½½çš„æ¨¡å‹æ˜¯ä¸å¸¦AWQçš„ï¼Œå³ä¾¿æ˜¯ä½ åœ¨ yml æ–‡ä»¶ä¸­å†™çš„ ä½¿ç”¨å¤šå¡GPUï¼Œä¹Ÿä¼šå®é™…ç”¨ä¸€ä¸ªGPUçš„æ˜¾å­˜ï¼Œææœ‰å¯èƒ½å‡ºç°æš´æ˜¾å­˜çš„æƒ…å†µã€‚![æˆªå±2025-03-20 09.33.12](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-20%2009.33.12.jpg)![æˆªå±2025-03-20 09.32.32](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-20%2009.32.32.jpg)

![æˆªå±2025-03-18 20.42.40](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-18%2020.42.40.jpg)

![æˆªå±2025-03-18 21.05.23](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-18%2021.05.23.jpg)

![æˆªå±2025-03-18 21.07.18](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-18%2021.07.18.jpg)

æ¨èä½¿ç”¨modelscope ä¸‹è½½åˆ°æŒ‡å®šä½ç½®ã€‚

![å¾®ä¿¡å›¾ç‰‡_20250318211815](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250318211815.png)



### 1.2ã€vllméƒ¨ç½²

#### 1.2.1ã€vllmå•æœºå¤šå¡éƒ¨ç½²

```sh
mkdir -p /home/cys/docker_data/vLLM
cd /home/cys/docker_data/vLLM

# nvcc --version å¦‚æœæ²¡æœ‰å°±å¦‚ä¸‹å®‰è£…ã€‚
# sudo apt update 
# sudo apt install nvidia-cuda-toolkit
vim hello.cu
# _____________________________ hello.cu ____________________________________
#include <cuda_runtime.h>
#include <stdio.h>

__global__ void hello() {
    printf("Hello from GPU!\n");
}

int main() {
    hello<<<1,1>>>();
    cudaDeviceSynchronize();
    return 0;
}
# _____________________________ hello.cu ____________________________________
nvcc --version #  release 12.0, V12.0.140  Build cuda_12.0.r12.0/compiler.32267302_0
nvcc -o hello hello.cu -arch=sm_86 && ./hello 
# è¾“å‡º Hello from GPU! ç®—æˆåŠŸã€‚

# åˆ›å»ºä¸€ä¸ªå¤–éƒ¨ç½‘ç»œ
docker network create vllm-network

vim docker-compose.yml
# _____________________________ docker-compose.yml ____________________________________
services:
  vllm-openai:
    runtime: nvidia
    restart: unless-stopped
    container_name: deepseek-container
    ipc: host  # ä½¿ç”¨ä¸»æœº IPC å‘½åç©ºé—´
    image: vllm/vllm-openai:latest
    volumes:
      - /home/cys/data/models/deepseek-r1-70b-AWQ:/models/deepseek-r1-70b:ro
    command:
      - "--model=/models/deepseek-r1-70b"
      - "--tensor_parallel_size=2"
      - "--pipeline_parallel_size=1"
      - "--gpu_memory_utilization=0.95"  # è°ƒé«˜åˆ©ç”¨ç‡ä»¥å¢åŠ  KV Cache å†…å­˜
      - "--max_model_len=8192"         # æ ¹æ®éœ€è¦è°ƒæ•´æœ€å¤§åºåˆ—é•¿åº¦
      - "--served-model-name=deepseek-r1-70b-AWQ"
      - "--dtype=half"
      - "--api-key=jisudf*&QW123"
      - "--swap_space=8"
    environment:
      - CUDA_VISIBLE_DEVICES=0,1
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
      - NCCL_DEBUG=INFO
    ports:
      - "8000:8000"
    deploy:  # é docker Swarm å†…ç½®é›†ç¾¤ æ¨¡å¼ä¸‹ï¼Œdeploy éƒ¨åˆ†çš„é…ç½®é€šå¸¸ä¸ä¼šè¢«åº”ç”¨
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 2
              capabilities: [gpu]
    networks:
      - my-network
    logging:
      driver: json-file
      options:
        max-size: "100m"
        max-file: "3"
networks:
  my-network:
    external: true
    name: vllm-network
# _____________________________ docker-compose.yml ____________________________________

docker compose up -d 
docker logs deepseek-container # æ£€æŸ¥å®¹å™¨æ—¥å¿—ï¼Œè¿˜å¯ä»¥æ£€æŸ¥ä¸€ä¸‹ã€‚nvidia-smi
```

![å¾®ä¿¡å›¾ç‰‡_20250320144426](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250320144426.png)

æ˜¾å¡è·‘èµ·æ¥äº†ï¼Œçœ‹è§ æ˜¾å­˜è¢«æèµ·æ¥äº†ï¼Œè¯´æ˜è°ƒç”¨æˆåŠŸã€‚

#### 1.2.2ã€vllmå¤šæœºå¤šå¡éƒ¨ç½²

å‚è€ƒï¼š

https://docs.vllm.ai/en/latest/serving/distributed_serving.html

https://mp.weixin.qq.com/s/tdubYmXNt98ZN6SB7iMIrw


å…ˆåœ¨å¦ä¸€å°æœºå™¨ä¸­å®‰è£…å¥½å’Œç¬¬ä¸€å°æœºå™¨ä¸€æ ·çš„ ç¯å¢ƒï¼ˆæ¨èdocker æï¼‰ï¼Œå½“ä»èŠ‚ç‚¹ã€‚

ä»ç¬¬ä¸€å°æœºå™¨ï¼ˆä¸»èŠ‚ç‚¹ï¼‰ä¸­æŠŠæ¨¡å‹å¤åˆ¶è¿‡æ¥ã€‚

ä¸‹è½½ä¸€ä¸ªvllm å®˜æ–¹çš„è„šæœ¬ï¼ˆclusterå¯åŠ¨è„šæœ¬ï¼‰ã€‚

```sh
wget https://github.com/vllm-project/vllm/blob/main/examples/online_serving/run_cluster.sh
```

##### 1.2.2.1ã€é€‰é¡¹ä¸€ï¼šé€šè¿‡swarméƒ¨ç½²

##### Docker Swarm é›†ç¾¤åŸºç¡€

å‚è€ƒï¼šhttps://www.bilibili.com/video/BV1ZM4m1Z75k/?spm_id_from=333.337.search-card.all.click&vd_source=a07523372ea1438247b770c295f20822

docker swarm å’Œ docker composeä¸€æ ·éƒ½æ˜¯ä¸ºäº†ç®€åŒ– å®¹å™¨åŒ–ç¨‹åºçš„éƒ¨ç½²ã€ç®¡ç†å’Œæ‰©å±•çš„å·¥å…·ã€‚

docker compose å•æœºä¸Šç”¨è€Œå·²ã€‚

docker swarm é›†ç¾¤ç”¨ã€‚

![æˆªå±2025-03-27 08.58.17](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2008.58.17.png)

![æˆªå±2025-03-27 09.02.04](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.02.04.png)

ä¸‹é¢çš„ä¾‹å­ æ˜¯ ä¸¤ä¸ª manager èŠ‚ç‚¹ ä¸¤ä¸ª worker èŠ‚ç‚¹ ç»„æˆçš„4ä¸ª node çš„ swarmé›†ç¾¤ä¾‹å­ã€‚

![æˆªå±2025-03-27 09.40.40](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.40.40.png)

###### Â· åˆå§‹åŒ–é›†ç¾¤ï¼š![æˆªå±2025-03-27 09.07.42](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.07.42.png)

###### Â· åŠ å…¥èŠ‚ç‚¹ï¼š

![æˆªå±2025-03-27 09.08.23](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.08.23.png)

docker node ls æŸ¥çœ‹ æœ‰å“ªäº›èŠ‚ç‚¹ã€‚

###### Â· é›†ç¾¤è§£æ•£ï¼š

![æˆªå±2025-03-27 09.11.50](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.11.50.png)



###### Â· èŠ‚ç‚¹ç®¡ç†ï¼š

![æˆªå±2025-03-27 09.15.37](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.15.37.png)

###### Â· æœåŠ¡ç®¡ç†ï¼š

![æˆªå±2025-03-27 09.20.15](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.20.15.png)

![æˆªå±2025-03-27 09.22.01](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.22.01.png)

> replicas æ˜¯ 2 è¯´æ˜ æäº†ä¸¤ä¸ªå‰¯æœ¬å®¹å™¨åœ¨é›†ç¾¤ä¸­ï¼Œä½†æ˜¯å…·ä½“åˆ†é…ç»™äº†å“ªä¸¤ä¸ªèŠ‚ç‚¹ ç”±è°ƒåº¦ç­–ç•¥æ¥å†³å®šï¼Œæ³¨æ„ä¸€å…±å°±æ˜¯ ä¸¤ä¸ªå®¹å™¨ ï¼Œå‰¯æœ¬çš„æ„æ€ä¸æ˜¯ è¯´å†å¤åˆ¶å‡º2ä¸ªä¸€å…±3ä¸ªï¼Œåˆ«è¯¯ä¼šäº†ã€‚
>
> source æ˜¯ å®¿ä¸»æœºçš„æ˜ å°„ç›®å½•ï¼Œtargetæ˜¯ å®¹å™¨å†…éƒ¨çš„ ç›®å½•ï¼Œç”¨bingç›´æ¥æ˜ å°„æŒ‚è½½ã€‚

![æˆªå±2025-03-27 09.35.18](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.35.18.png)

> docker service ls çœ‹è§ å±æ€§ä¸­çš„ replicas 2/2 3/3 1/1 5/5 å‰åæ•°å­—ä¸€è‡´ è¯´æ˜æœ‰2ä¸ªreplicaså‰¯æœ¬ï¼Œæœ‰2ä¸ªæˆåŠŸè¿è¡Œï¼Œä»¥æ­¤ç±»æ¨ã€‚å‰åä¸ä¸€è‡´è¯´æ˜æ²¡æœ‰æ­£å¸¸è¿è¡Œã€‚

>  æœåŠ¡å®šä¹‰å¥½ä»¥åï¼Œæ˜¯åœ¨é›†ç¾¤ä¸­çš„å…¨éƒ¨ node éƒ½èƒ½è®¿é—®çš„ï¼Œä½†æ˜¯å®¹å™¨å¹¶ä¸æ˜¯åœ¨æ¯ä¸€ä¸ªèŠ‚ç‚¹ä¸­è¿è¡Œï¼Œä»…ä»…æ˜¯åœ¨è°ƒåº¦åˆ†é…çš„èŠ‚ç‚¹ä¸­è¿è¡Œã€‚

###### Â· swarmé›†ç¾¤å¼¹æ€§ä¼¸ç¼©ï¼š

![æˆªå±2025-03-27 09.53.01](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.53.01.png)

###### Â· swarmé›†ç¾¤æœåŠ¡æ»šåŠ¨æ›´æ–°ï¼š

![æˆªå±2025-03-27 09.56.58](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.56.58.png)

```sh
docker service update --replicas=5
--image mysql:8.0
--update-delay 60s
--update-parallelism 5
mydb
```

![æˆªå±2025-03-27 10.04.10](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2010.04.10.png)

60ç§’å 4ä¸ªnode ä¸­å‡ºç°äº†5ä¸ªæ›´æ–°åˆ° mysql8.0çš„æœåŠ¡å®¹å™¨ã€‚

![æˆªå±2025-03-27 10.05.33](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2010.05.33.png)

###### Â· swarmé›†ç¾¤ä¸­ä½¿ç”¨docker composeï¼š

![æˆªå±2025-03-27 10.45.28](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2010.45.28.png)

![æˆªå±2025-03-27 10.46.19](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2010.46.19.png)

> å¯ä»¥æŠŠ è¿™ä¹ˆå¤šä¸ªå‰¯æœ¬å…¨éƒ¨è½åˆ°æŒ‡å®šçš„node èŠ‚ç‚¹ä¸­ã€‚
>
> docker compose up æ˜¯å•æœºå¯åŠ¨æ–¹å¼ï¼Œä¼šå¿½ç•¥ deploy å†…å®¹ã€‚

![æˆªå±2025-03-27 10.53.38](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2010.53.38.png)

```sh
docker stack deploy -c ymlæ–‡ä»¶å è‡ªå®šä¹‰stackå
```

docker swarm ä¸­ä¸æ”¯æŒ name å±æ€§çš„å®šä¹‰
![æˆªå±2025-03-27 13.55.39](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2013.55.39.png)

docker swarm å’Œ k8s æ˜¯ç«äº‰å…³ç³»ï¼Œä½†æ˜¯ docker swarm æ²¡æœ‰ç«äº‰è¿‡k8sï¼Œä½†æ˜¯docker swarmä¾ç„¶æœ‰å®ƒçš„æ„ä¹‰ã€‚



##### å…·ä½“æ“ä½œ

åœ¨ Docker Swarm çš„é›†ç¾¤æ¶æ„ä¸­ï¼Œ**æ‰€æœ‰ YAML æ–‡ä»¶éƒ½éœ€è¦åœ¨ä¸»èŠ‚ç‚¹ä¸Šè¿è¡Œ**ã€‚

###### Â· docker swarm GPUæ”¯æŒ

å‚è€ƒ  https://gist.github.com/coltonbh/374c415517dbeb4a6aa92f462b9eb287

å¯¹ä¸»ä»èŠ‚ç‚¹æ¯ä¸€å°æœºå™¨ä½œå¦‚ä¸‹æ“ä½œï¼š

```sh
nvidia-smi -a # æŸ¥çœ‹ GPUçš„å…·ä½“ uuid

sudo vim /etc/docker/daemon.json
# æ”¹æˆå¦‚ä¸‹
# NVIDIA-GPU åå­—æ˜¯å¯ä»¥è‡ªå®šä¹‰çš„ï¼Œè°ƒç”¨çš„æ—¶å€™æ³¨æ„ç‚¹ã€‚
------------------------------------ daemon.json ------------------------------------
{
    "registry-mirrors": [
        "https://docker.m.daocloud.io",
        "https://mirror.ccs.tencentyun.com",
        "https://func.ink",
        "https://proxy.1panel.live",
        "https://docker.zhai.cm"
    ],
    "default-runtime": "nvidia",
    "runtimes": {
      "nvidia": {
        "path": "nvidia-container-runtime",
        "runtimeArgs": []
        }
    },
    "node-generic-resources": [
      "NVIDIA-GPU=GPU-c8fcc40e-7aef-0401-1519-2e8b2ef1521b",
      "NVIDIA-GPU=GPU-a27b8ea5-b0bf-3a21-90ff-e9417f58ff11"
      ]
}
------------------------------------ daemon.json ------------------------------------
```

åœ¨ä¸»èŠ‚ç‚¹æœºå™¨ä¸­ ç¼–è¾‘ vllm-head.yml vllm-worker1.yml vllm-worker1.yml ç­‰

```sh
vim vllm-head.yml 

services:
  vllm-head:
    image: vllm/vllm-openai:latest
    #container_name: vllm-head
    restart: unless-stopped
    command:
      - "--head"
      - "--model=/models/deepseek-r1-70b"
      - "--tensor_parallel_size=2"         # å•æœº GPU æ•°ï¼ˆ2å¡å¹¶è¡Œï¼‰
      - "--pipeline_parallel_size=2"       # æ€»èŠ‚ç‚¹æ•°ï¼ˆä¸»+1ä»ï¼‰
      - "--served-model-name=deepseek-r1-70b-AWQ"
      - "--max-model-len=8192"
      - # åŠ ä¸Šä¸€äº›çº¦æŸæ¡ä»¶ï¼Œè®© æ˜¾å­˜ä¸è¦è·‘çˆ†äº†ï¼Œæ‰èƒ½æ­£å¸¸å¯åŠ¨ï¼Œå¯ä»¥å‚è€ƒå•æœºæƒ…å†µã€‚
    volumes:
      - /home/cys/data/models/deepseek-r1-70b-AWQ:/models/deepseek-r1-70b-AWQ:ro
    environment:
      #- NVIDIA_VISIBLE_DEVICES=all         # è®©å®¹å™¨èƒ½è®¿é—®æ‰€æœ‰ GPU
      #- NVIDIA_DRIVER_CAPABILITIES=all
      - CUDA_VISIBLE_DEVICES=0,1           # åªä½¿ç”¨ 0 å’Œ 1 å· GPU
      #- NVIDIA_VISIBLE_DEVICES=0,1
      - VLLM_HOST_IP=10.5.9.252            # ä¸»èŠ‚ç‚¹ IP
      - RAY_HEAD_IP=10.5.9.252             # Ray é€šä¿¡åœ°å€
      - RAY_HEAD_PORT=6379
      - NCCL_SOCKET_IFNAME=enp1s0          # è·¨èŠ‚ç‚¹é€šä¿¡æ¥å£
    ports:
      - "8000:8000"
      - "6379:6379"
    networks:
      vllm-cluster:
        ipv4_address: 10.10.0.100
    deploy:
      placement:
        constraints:
          - node.hostname == cysserver     # # åªåœ¨ æŒ‡å®š  çš„èŠ‚ç‚¹ä¸Šè¿è¡Œ
      resources:
        reservations:
          generic_resources:
            - discrete_resource_spec:
                kind: "nvidia-gpu"         #"NVIDIA-GPU"
                value: 2
networks:
  vllm-cluster:
    driver: overlay
    ipam:
      config:
        - subnet: 10.10.0.0/24
```

```sh
vim vllm-worker.yml
# å¯¹ deploy éƒ¨åˆ† åšç±»ä¼¼ä¸Šé¢çš„ä¿®æ”¹ã€‚

services:
  vllm-worker:
    runtime: nvidia
    image: vllm/vllm-openai:latest
    #container_name: vllm-worker
    restart: unless-stopped
    command:
      - "--worker"
      - "--model=/models/deepseek-r1-70b"
    volumes:
      - /home/cys/models/deepseek-r1-70b-AWQ:/models/deepseek-r1-70b:ro
    environment:
      - CUDA_VISIBLE_DEVICES=1             # ä»…ä½¿ç”¨ç¬¬äºŒå— GPU
      - RAY_HEAD_IP=10.5.9.252:6379        # æŒ‡å‘ä¸»èŠ‚ç‚¹
      - NCCL_SOCKET_IFNAME=eno1            # é€šä¿¡ç½‘å¡æ¥å£
    networks:
      vllm-cluster:
        ipv4_address: 10.10.0.101          # ä¸åŒä»èŠ‚ç‚¹éœ€ä¿®æ”¹ IP
    deploy:
      placement:
        constraints:
          - node.hostname == cys           # å¼ºåˆ¶åªåœ¨åä¸ºcysçš„èŠ‚ç‚¹è¿è¡Œ
          #- node.labels.gpu == 1           # ç¡®ä¿ä»èŠ‚ç‚¹æœ‰ 1 å— GPU
       # å¯¹ deploy éƒ¨åˆ† åšç±»ä¼¼ä¸Šé¢ä¸»èŠ‚ç‚¹çš„ä¿®æ”¹ã€‚
networks:
  vllm-cluster:
    external: true                         # å¤ç”¨ä¸»èŠ‚ç‚¹ç½‘ç»œ
    name: vllm-cluster
```

åŠ æ ‡ç­¾ï¼Œyml æ–‡ä»¶ä¸­æœ‰é€šè¿‡æ ‡ç­¾ æŒ‡å®šæœåŠ¡å…·ä½“è½åœ¨çš„å“ªä¸ªèŠ‚ç‚¹ã€‚

```sh
 docker node update --label-add node.hostname=cys cys
 docker node update --label-add node.hostname=cysserver cysserver
```

åœ¨ä¸»èŠ‚ç‚¹æœºå™¨ä¸Š ä½œ swarm åˆå§‹åŒ–ï¼Œç„¶ååœ¨å„ä¸ªä»èŠ‚ç‚¹ ä»¥workerèº«ä»½åŠ å…¥ warm é›†ç¾¤ã€‚

å…·ä½“æ“ä½œ å‚è€ƒ ä»€ä¹ˆçš„Docker SwarmåŸºç¡€ã€‚

###### é—®é¢˜ï¼š

é€šè¿‡ docker swarm é›†ç¾¤éƒ¨ç½²çš„ å¤§æ¨¡å‹ï¼Œå¹¶æ²¡æœ‰å®ç° å¯¹ç®—åŠ›èµ„æºçš„ æ±‡æ€»ï¼Œè€Œä»…ä»…æ˜¯åƒä¸€ä¸ªæ™®é€šçš„åˆ†å¸ƒå¼åº”ç”¨ä¸€æ ·é€‰æ‹©æŠŠæœåŠ¡éƒ¨ç½²åœ¨å“ªä¸€ä¸ªèŠ‚ç‚¹ä¸­è¿è¡Œï¼Œé¡¶å¤šåªæ˜¯ è¿™ä¸ªèŠ‚ç‚¹åäº†ï¼Œæœ‰ä¸€ä¸ª æ–°èŠ‚ç‚¹ è¡¥å…… ç±»ä¼¼è¿™æ ·ã€‚

å¦‚æœæ¯ä¸€ä¸ªèŠ‚ç‚¹çš„GPU èµ„æºéƒ½ä¸è¶³ä»¥éƒ¨ç½²æ­¤å¤§æ¨¡å‹ï¼Œ é‚£è¿™æ ·çš„ docker swarm é›†ç¾¤éƒ¨ç½² å¤§æ¨¡å‹æ— æ³•æˆåŠŸï¼Œæ‰€ä»¥è¿™ç§ é›†ç¾¤åˆ†å¸ƒå¼éƒ¨ç½²ä¸æ˜¯æˆ‘ä»¬è¦çš„ æ–¹å¼ã€‚

é‚£æˆ‘ä»¬åº”è¯¥ç”¨å“ªä¸€ç§ åˆ†å¸ƒå¼çš„éƒ¨ç½²æ–¹å¼å‘¢ï¼Ÿ

ç­”æ¡ˆå°±åœ¨vllm çš„å®˜ç½‘ä¸­ï¼Œå…¶å® ä¸‹è½½ vllm github ä¸­çš„ åˆ†å¸ƒå¼éƒ¨ç½²è„šæœ¬ï¼Œå¯ä»¥ç”¨å®ƒè‡ªå¸¦çš„ray é›†ç¾¤å®ç°å¯¹èµ„æºçš„æ•´åˆè°ƒåº¦ã€‚

##### 1.2.2.2ã€é€‰é¡¹äºŒï¼šé€šè¿‡ ray é›†ç¾¤éƒ¨ç½²

å‚è€ƒï¼šhttps://docs.vllm.ai/en/latest/serving/distributed_serving.html
https://mp.weixin.qq.com/s/fflQZOcNCAcltpzm6hB7AA

https://mp.weixin.qq.com/s/tdubYmXNt98ZN6SB7iMIrw

![æˆªå±2025-03-30 18.37.48](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-30%2018.37.48.jpg)

ä¸Šé¢çš„swarmé›†ç¾¤éƒ¨ç½²è§£å†³ä¸äº†èµ„æºæ•´åˆçš„ é—®é¢˜å¯¼è‡´äº†å•ä¸ªèŠ‚ç‚¹èµ„æºä¸è¶³å°±æ— æ³•åœ¨è¿™ä¸ªèŠ‚ç‚¹éƒ¨ç½²æœåŠ¡ã€‚

ä¸ºäº†è§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬ç”¨vllm æ¨èçš„ åˆ†å¸ƒå¼éƒ¨ç½²æ–¹å¼ã€‚ï¼ˆæˆ‘åœ¨swarm é›†ç¾¤éƒ¨ç½²ä¸Šé¢ç»•äº†ä¸€ä¸ªå¥½å¤§çš„å¼¯ï¼Œä»¥åéƒ½ä¼˜å…ˆä½¿ç”¨å®˜ç½‘æ¨èçš„æœ€ä½³å®è·µï¼Œä¸è¦è‡ªå·±æŠ˜è…¾ï¼Œè´¹åŠ²ä¸è®¨å¥½ã€‚ï¼‰

ä¸‹è½½å®˜æ–¹å¤šèŠ‚ç‚¹è„šæœ¬åˆ°æœ¬åœ°

```sh
cd /home/cys/docker_data/vLLM

# ç½‘é¡µä¸Šçš„ blob æ”¹æˆ raw å°±èƒ½ç›´æ¥å“Ÿä¸ª wget ä¸‹è½½ä¸‹æ¥ã€‚
# https://github.com/vllm-project/vllm/blob/main/examples/online_serving/run_cluster.sh
wget https://github.com/vllm-project/vllm/raw/main/examples/online_serving/run_cluster.sh
```

**éƒ¨ç½²rayé›†ç¾¤**

**ä¸»èŠ‚ç‚¹10.5.9.252**

```sh
bash run_cluster.sh \
                vllm/vllm-openai \
                10.5.9.252 \
                --head \
                /home/cys/data/models/deepseek-r1-70b-AWQ \
                -v /home/cys/data/models/deepseek-r1-70b-AWQ/:/model/deepseek-r1-70b-AWQ/ \
                -e VLLM_HOST_IP=10.5.9.252 \
                -e GLOO_SOCKET_IFNAME=enp1s0 \
                -e NCCL_SOCKET_IFNAME=enp1s0
```

> enp1s0 æ˜¯ çœ‹ip èµ°é‚£ä¸ªç½‘å£ å¾—å‡ºçš„

![å¾®ä¿¡å›¾ç‰‡_20250330182312](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330182312.png)

æ­¤æ—¶å†å¼€ä¸€ä¸ªçª—å£ï¼Œè¿›å…¥ä¸»èŠ‚ç‚¹çš„å®¹å™¨ä¸­æŸ¥çœ‹ray é›†ç¾¤ã€‚

```sh
docker exec -it f474c557b8a6 /bin/bash
root@cysserver:/vllm-workspace# ray status 
======== Autoscaler status: 2025-03-30 03:27:55.102175 ========
Node status
---------------------------------------------------------------
Active:
 1 node_8e51bfc57e87e7c4c7c44817444eabd64c1b2fd109e67d065110c5a1
Pending:
 (no pending nodes)
Recent failures:
 (no failures)

Resources
---------------------------------------------------------------
Usage:
 0.0/24.0 CPU
 0.0/2.0 GPU
 0B/484.01GiB memory
 0B/9.73GiB object_store_memory

Demands:
 (no resource demands)
```

**ä»èŠ‚ç‚¹10.5.9.253**

```sh
å…ˆç»Ÿä¸€ ray ç‰ˆæœ¬
# ä¸»ä»èŠ‚ç‚¹ä¹‹é—´ï¼Œvllm-openai é•œåƒç‰ˆæœ¬å·®å¼‚å¯¼è‡´ Ray ç‰ˆæœ¬ä¸åŒï¼Œæ¨è 
# docker save -o vllm.tar vllm/vllm-openai:dddddddç‰ˆæœ¬åœ¨docker ps -aæŸ¥çœ‹ï¼Œå¯ä»¥æ˜¯latest
# md5sum vllm.tar > vllm.tar.md5
# ä¼ è¾“è¿‡ï¼Œè¿å¸¦ç€md5æ–‡ä»¶ã€‚scp vllm.tar* cys@10.5.9.252:/home/cys/data/models/docker-images-warehouse
# åœ¨æœºå™¨2æ‰§è¡Œ
# cd /home/cys/data/models/docker-images-warehouse
# éªŒè¯ md5sum -c vllm.tar.md5 çœ‹çœ‹okä¸okã€‚
# åˆ é™¤ è€çš„ç‰ˆæœ¬çš„ vllm ï¼Œdocker rmi XXXXXXX  
# docker load -i vllm.tar

```

```sh
bash run_cluster.sh \
                vllm/vllm-openai \
                10.5.9.252 \
                --worker \
                /home/cys/models/deepseek-r1-70b-AWQ \
                -v /home/cys/models/deepseek-r1-70b-AWQ/:/model/deepseek-r1-70b-AWQ/ \
                -e VLLM_HOST_IP=10.5.9.253 \
                -e GLOO_SOCKET_IFNAME=eno1 \
                -e NCCL_SOCKET_IFNAME=eno1
```

> eno1 æ˜¯ çœ‹ip èµ°é‚£ä¸ªç½‘å£ å¾—å‡ºçš„

æ­¤æ—¶å†å¼€ä¸€ä¸ªçª—å£ï¼Œè¿›å…¥ä¸»èŠ‚ç‚¹çš„å®¹å™¨ä¸­æŸ¥çœ‹ray é›†ç¾¤ã€‚

```sh
docker exec -it f474c557b8a6 /bin/bash
root@cysserver:/vllm-workspace# ray status 
======== Autoscaler status: 2025-03-30 11:21:02.211262 ========
Node status
---------------------------------------------------------------
Active:
 1 node_921f86c035112492b0daccabd0f373361ea3a721370c3cbcc1dc32ea
 1 node_4260699a5c1bfdf24d9a886b7aec5e38b7f5e42ab38a2427c13e8366
Pending:
 (no pending nodes)
Recent failures:
 (no failures)

Resources
---------------------------------------------------------------
Usage:
 0.0/48.0 CPU
 0.0/4.0 GPU
 0B/725.54GiB memory
 0B/19.46GiB object_store_memory

Demands:
 (no resource demands)
```

åœ¨rayé›†ç¾¤éƒ¨ç½²å¥½ä¹‹åå¯ä»¥çœ‹è§ï¼Œåœ¨ä¸€å°æœºå™¨ä¸Šå¯ä»¥è°ƒç”¨æ•´ä¸ªé›†ç¾¤çš„èµ„æºäº†ã€‚
åœ¨ä¸»èŠ‚ç‚¹è¿›å…¥vllmçš„å®¹å™¨ï¼Œå¯åŠ¨ vllm æœåŠ¡

```sh
docker exec -it f474c557b8a6 /bin/bash
# --tensor-parallel-size å•å°æœºå™¨çš„GPUæ•°é‡ï¼Œ--pipeline-parallel-size èŠ‚ç‚¹æ•°é‡ï¼Œvllm GPUåªèƒ½1 2 4 8 è¿™æ ·çš„æ€»æ•°é‡è¿è¡Œã€‚
 vllm serve /model/deepseek-r1-70b-AWQ \
     --tensor-parallel-size 2 \
     --pipeline-parallel-size 2 \
     --max-model-len 53520 \
     --gpu-memory-utilization 0.8 \
     --served-model-name deepseek-r1-70b-AWQ \
     --api-key 'jisudf*&QW123'
```

![å¾®ä¿¡å›¾ç‰‡_20250330222345](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330222345.png)



### 1.3ã€åµŒå…¥æ¨¡å‹éƒ¨ç½²

å‚è€ƒï¼š https://blog.csdn.net/make_progress/article/details/146051006

https://github.com/huggingface/text-embeddings-inference



æ–‡æœ¬åµŒå…¥æ¨ç†ï¼ˆTEIï¼ŒText Embeddings Inference ï¼‰æ˜¯HuggingFaceç ”å‘çš„ä¸€ä¸ªç”¨äºéƒ¨ç½²å’ŒæœåŠ¡å¼€æºæ–‡æœ¬åµŒå…¥å’Œåºåˆ—[åˆ†ç±»æ¨¡å‹](https://so.csdn.net/so/search?q=åˆ†ç±»æ¨¡å‹&spm=1001.2101.3001.7020)çš„å·¥å…·åŒ…ã€‚TEIå…¼å®¹OpenAIçš„åµŒå…¥æ¨¡å‹çš„è§„èŒƒã€‚ æˆ‘ä»¬ç”¨åˆ°çš„å°±æ˜¯å®ƒã€‚
æˆ‘ä»¬é€‰ç”¨ bge-large-zh-v1.5 æ¨¡å‹ã€‚

å…ˆåœ¨å›½å†…çš„ModelScopeä¸Šä¸‹è½½BAAI/bge-reranker-largeæ¨¡å‹ï¼›

```sh
modelscope download --model BAAI/bge-large-zh-v1.5 --local_dir /home/cys/data/models/embeddingModel/.    
```

å»ºç«‹ä¸€ä¸ª docker å®¹å™¨ä¸“é—¨æä¾›åµŒå…¥æœåŠ¡ï¼›

```sh
cd /home/cys/docker_data/embeddingModel
mkdir -p bge-large-zh-v1.5
cd /home/cys/docker_data/embeddingModel/bge-large-zh-v1.5

vim docker-compose.yml
------------------------------ docker-compose.yml ------------------------------
services:
  text-embeddings-inference:
    user: "0:0"
    image: ghcr.io/huggingface/text-embeddings-inference:1.6
    #runtime: nvidia
    ports:
      - "8002:80"
    volumes:
      - "/home/cys/data/models/embeddingModel:/data"  # bge-large-zh-v1.5:/data"
    environment:
      - EMBEDDING_API_KEY=wiekdoid@JIDj124123
    command: ["--model-id", "/data/bge-large-zh-v1.5", "--auto-truncate"]
    networks:
      - my-network  # ç›´æ¥å¼•ç”¨å·²å­˜åœ¨çš„ç½‘ç»œ

networks:
  my-network:
    external: true  # åªå¼•ç”¨å¤–éƒ¨å·²å­˜åœ¨çš„ç½‘ç»œ
    name: vllm-network
------------------------------ docker-compose.yml ------------------------------

docker compose up -d
```

æ£€æŸ¥æ˜¯å¦å¯ç”¨

```sh
curl -X POST "http://localhost:8002/embed" -H "Content-Type: application/json" -d '{
  "inputs": ["ä½ å¥½ï¼Œä¸–ç•Œ"],
  "truncate": false
}'
# çœ‹çœ‹ ä¼šä¸ä¼šè¿”å›falseã€‚
```

æ³¨æ„ï¼šTEIå½“å‰ä¸ä¼šè‡ªåŠ¨æˆªæ–­è¾“å…¥ã€‚æ‚¨å¯ä»¥é€šè¿‡åœ¨è¯·æ±‚ä¸­è®¾ç½®`truncate: true`æ¥å¯ç”¨æ­¤åŠŸèƒ½ã€‚

åœ¨å®˜ç½‘githubä¸­å¯è§ 

```sh
      --auto-truncate
          Automatically truncate inputs that are longer than the maximum supported size

          Unused for gRPC servers

          [env: AUTO_TRUNCATE=]
```



### 1.4ã€open webUIè°ƒç”¨vllm

```sh
mkdir -p /home/cys/docker_data/openwebui2
cd /home/cys/docker_data/openwebui2

vim docker-compose.yml 
# _____________________________ docker-compose.yml ____________________________________
services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:cuda
    environment:
      # ç¦ç”¨ ollama è¿æ¥ï¼ˆæ³¨é‡Šæˆ–åˆ é™¤è¯¥è¡Œï¼‰
      # - OLLAMA_API_BASE_URL=http://10.5.9.252:11434
      
      # å¯ç”¨ OpenAI å…¼å®¹ APIï¼ˆå¿…é¡»å¼€å¯ï¼‰
      - ENABLE_OPENAI_API=true
      
      # æŒ‡å‘æœ¬åœ° vLLM çš„ OpenAI å…¼å®¹æ¥å£,å³ä½¿ä½ è®¾ç½® container_name ä¸º deepseek-containerï¼ŒDockerå†…éƒ¨ä»ç„¶ä¼šå°†è¿™ä¸ªå®¹å™¨æ³¨å†Œä¸ºæœåŠ¡å vllm-openaiï¼Œæ‰€ä»¥å…¶ä»–åŒç½‘ç»œçš„å®¹å™¨å¯ä»¥é€šè¿‡ â€œvllm-openaiâ€ è®¿é—®å®ƒ
      # è¿™é‡Œçœ‹å‰é¢vllmä¸­æ€ä¹ˆå†™ï¼Œå¦‚æœå†™äº†http://10.5.9.252:8000/v1 è¿™é‡Œä¹Ÿè¦å†™è¿™ä¸ªã€‚
      - OPENAI_API_BASE_URL=http://vllm-openai:8000/v1     
      
      # è®¾ç½®ä¸ vLLM ä¸€è‡´çš„ API å¯†é’¥
      - OPENAI_API_KEYS=jisudf*&QW123
      
      # å…¶ä»–åŸæœ‰é…ç½®ä¿æŒä¸å˜
      - GLOBAL_LOG_LEVEL=DEBUG
      - HF_ENDPOINT=https://hf-mirror.com
      - CORS_ALLOW_ORIGIN=*
      - RAG_EMBEDDING_MODEL=bge-m3
      - DEFAULT_MODELS=deepseek-r1-70b-AWQ  # éœ€ä¸ vLLM çš„ --served-model-name å‚æ•°ä¸€è‡´
      - ENABLE_OAUTH_SIGNUP=true
    ports:
      - 8080:8080
    volumes:
      - /home/cys/data/docker-data/open_webui_data:/app/backend/data
    networks:
      - my-network
networks:
  my-network:
    external: true
    name: vllm-network
# _____________________________ docker-compose.yml ____________________________________

docker compose up -d 

```

å†åœ¨webé¡µé¢é…ç½®ä¸€ä¸‹è¿æ¥ä¸Š vllm ã€‚
![å¾®ä¿¡å›¾ç‰‡_20250320155359](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250320155359.png)

![å¾®ä¿¡å›¾ç‰‡_20250320155402](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250320155402.png)

åˆ†å¸ƒå¼vllm ï¼Œopen webUIå¦‚ä¸‹ï¼š

docker-compose.yml

```yaml
services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:cuda
    environment:
      # ç¦ç”¨ ollama è¿æ¥ï¼ˆæ³¨é‡Šæˆ–åˆ é™¤è¯¥è¡Œï¼‰
      # - OLLAMA_API_BASE_URL=http://10.5.9.252:11434
      
      # å¯ç”¨ OpenAI å…¼å®¹ APIï¼ˆå¿…é¡»å¼€å¯ï¼‰
      - ENABLE_OPENAI_API=true
      
      # æŒ‡å‘æœ¬åœ° vLLM çš„ OpenAI å…¼å®¹æ¥å£,å³ä½¿ä½ è®¾ç½® container_name ä¸º deepseek-containerï¼ŒDockerå†…éƒ¨ä»ç„¶ä¼šå°†è¿™ä¸ªå®¹å™¨æ³¨å†Œä¸ºæœåŠ¡å vllm-openaiï¼Œæ‰€ä»¥å…¶ä»–åŒç½‘ç»œçš„å®¹å™¨å¯ä»¥é€šè¿‡ â€œvllm-openaiâ€ è®¿é—®å®ƒ
      - OPENAI_API_BASE_URL=http://vllm-openai:8000/v1
      
      # è®¾ç½®ä¸ vLLM ä¸€è‡´çš„ API å¯†é’¥
      - OPENAI_API_KEYS=jisudf*&QW123
      
      # å…¶ä»–åŸæœ‰é…ç½®ä¿æŒä¸å˜
      - GLOBAL_LOG_LEVEL=DEBUG
      - HF_ENDPOINT=https://hf-mirror.com
      - CORS_ALLOW_ORIGIN=*
      - RAG_EMBEDDING_MODEL=bge-m3
      - DEFAULT_MODELS=deepseek-r1-70b-AWQ  # éœ€ä¸ vLLM çš„ --served-model-name å‚æ•°ä¸€è‡´
      - ENABLE_OAUTH_SIGNUP=true
      # è®¾ç½®é»˜è®¤çš„ Embedding æ¨¡å‹åç§°ï¼ˆç”¨äºå†…éƒ¨è®°å½•æˆ–æ—¥å¿—ï¼‰
      - RAG_EMBEDDING_MODEL=bge-large-zh-v1.5
      # æŒ‡å®š Embedding API æœåŠ¡çš„åœ°å€ï¼Œç¡®ä¿è¯¥åœ°å€åœ¨åŒä¸€ç½‘ç»œå†…å¯è®¿é—®
      - EMBEDDING_API_BASE_URL=http://10.5.9.252:8002/v1
      - EMBEDDING_API_KEYS=wiekdoid@JIDj124123     # è¿™é‡Œç”¨ç›¸åŒçš„ Key å…³è”ä¸Š
    ports:
      - 8080:8080
    volumes:
      - /home/cys/data/docker-data/open_webui_data:/app/backend/data
    networks:
      - my-network
networks:
  my-network:
    external: true
    name: vllm-network
```

> ä»¥ä¸ŠåŠ å…¥äº† åµŒå…¥æ¨¡å‹çš„è°ƒç”¨ï¼Œåˆ«çš„æ²¡æœ‰å¤ªå¤§å˜åŒ–ã€‚

è®°å¾—åœ¨open webUI webç®¡ç†ç•Œé¢æ·»åŠ  åµŒå…¥æ¨¡å‹ã€‚

![å¾®ä¿¡å›¾ç‰‡_20250402181950](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250402181950-3589288.png)









# é™„åŠ ï¼šå¯èƒ½é‡åˆ°çš„è‹¥å¹²é—®é¢˜ï¼š

```sh
# é€šè¿‡ docker compose down å‘½ä»¤åœæ­¢å½“å‰è¿è¡Œçš„æ‰€æœ‰å®¹å™¨ï¼ŒåŒæ—¶æ¸…ç†ç½‘ç»œå’Œå®¹å™¨èµ„æºï¼ˆé»˜è®¤ä¿ç•™æ•°æ®å·ï¼‰
docker compose down
# ä½¿ç”¨ docker compose up -d é‡æ–°æ„å»ºå¹¶å¯åŠ¨å®¹å™¨ï¼ˆè‡ªåŠ¨åº”ç”¨æœ€æ–°é…ç½®ï¼‰
docker compose up -d
```

```sh
# åœæ­¢æ‰€æœ‰å®¹å™¨
docker compose stop
# ä¿®æ”¹ YAML æ–‡ä»¶åé‡å¯
docker compose up -d
```

```sh
# è‹¥ä»…ä¿®æ”¹æŸä¸€æœåŠ¡çš„é…ç½®ï¼Œå¯å•ç‹¬é‡å¯è¯¥æœåŠ¡ï¼ˆé¿å…å½±å“å…¶ä»–æœåŠ¡ï¼‰
docker compose up -d --no-deps <æœåŠ¡å>
```

```yaml
# çœ‹çœ‹ æ­¤é¡¹ç›®æ–‡ä»¶å¤¹ä¸‹æœ‰å“ªäº› docker compose æœåŠ¡åœ¨è¿è¡Œ
docker compose ps
```

#### Â· AnythingLLMæ•°æ®è¿ç§»

å¦‚æœæ˜¯ ä¹‹å‰ æ‹‰å–anythingllm æ²¡æœ‰åšæœ¬åœ°çš„æ˜ å°„ï¼Œåœ¨æ›´æ–°anythingllm çš„æ—¶å€™ï¼Œä¸€å®šè¦åšå¥½ æ•°æ®çš„è½¬ç§»ã€‚

```sh
docker start AnythingLLM

# åˆ›å»ºä¸´æ—¶å¤‡ä»½ç›®å½•
mkdir ~/anythingllm_backup

# å°†å®¹å™¨å†…æ•°æ®æ‹·è´åˆ°å®¿ä¸»æœºï¼ˆéœ€å®¹å™¨ä»åœ¨è¿è¡Œï¼‰
docker cp AnythingLLM:/app/server/storage XXXXXXXXX/anythingllm
# æ³¨æ„ï¼šä¸€å®šè¦å°† .env æ–‡ä»¶å•ç‹¬ æŒªåˆ° XXXXXXXXX/anythingllm å¹¶æ£€æŸ¥å‡ ä¸ªsig_key sig_saltå…¶ä»–å¯†é’¥ã€‚
cp XXXXX/XXXX/.env XXXXXXXXX/anythingllm  # é‡è¦ï¼ï¼ï¼ï¼ï¼

export STORAGE_LOCATION=XXXXXXXXX/anythingllm  # å®šä¹‰å­˜å‚¨è·¯å¾„å˜é‡
mkdir -p $STORAGE_LOCATION && chmod -R 777 $STORAGE_LOCATION  # åˆ›å»ºç›®å½•å¹¶èµ‹æƒ


cp -r ~/anythingllm_backup/* $STORAGE_LOCATION/
cp -r ~/anythingllm_backup/storage/* $STORAGE_LOCATION/

docker ps -a  # æ˜¾ç¤ºæ‰€æœ‰å®¹å™¨
docker stop AnythingLLM 

docker rm AnythingLLM

docker images
docker rmi <æ—§é•œåƒID>

docker stop AnythingLLM && docker rm AnythingLLM  # æ¸…ç†æ—§å®¹å™¨
docker pull mintplexlabs/anythingllm:latest
export STORAGE_LOCATION=/home/cys/docker_data/anythingllm  # ç¡®ä¿ä¸åŸè·¯å¾„ä¸€è‡´


mkdir -p $STORAGE_LOCATION
cd ${STORAGE_LOCATION}
touch .env

docker run -d -p 3001:3001 \
  --name AnythingLLM \
  --network host \
  --cap-add SYS_ADMIN \
  -v ${STORAGE_LOCATION}:/app/server/storage \
  -v ${STORAGE_LOCATION}/.env:/app/server/.env \
  -e STORAGE_DIR="/app/server/storage" \
  mintplexlabs/anythingllm

```

#### Â· æµ‹è¯•å®¹å™¨ä¹‹é—´æ˜¯å¦ç›¸é€š

```sh
docker exec -it AnythingLLM /bin/bash


curl "http://å®¿ä¸»æœºIP:ç«¯å£/search?q=æµ‹è¯•&format=json" 
# çœ‹çœ‹ä»ä¸€ä¸ªå®¹å™¨ä¸­è°ƒç”¨å¦ä¸€ä¸ªå®¹å™¨åˆ°å®¿ä¸»æœºçš„åŠŸèƒ½æ˜¯ä¸æ˜¯èƒ½ç”¨ï¼Œå› ä¸ºsearxngå®¹å™¨å·²ç»æ˜ å°„äº†è‡ªå·±çš„æœç´¢åŠŸèƒ½åˆ°å®¿ä¸»æœºçš„8080ç«¯å£ï¼Œæ‰€ä»¥è¿™é‡Œç”¨å®¿ä¸»æœº8080ç«¯å£å³å¯æµ‹è¯•ã€‚

```

#### Â· é‡åˆ° **é˜¿é‡Œäº‘ Docker CE é•œåƒæº** å’Œ **GPG å¯†é’¥è¿‡æ—¶** 

```sh
sudo apt-get update 

# é‡åˆ°æŠ¥é”™
W: An error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: https://mirrors.aliyun.com/docker-ce/linux/ubuntu noble InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 7EA0A9C3F273FCD8
W: https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu/dists/noble/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.
W: Failed to fetch https://mirrors.aliyun.com/docker-ce/linux/ubuntu/dists/noble/InRelease  The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 7EA0A9C3F273FCD8
W: Some index files failed to download. They have been ignored, or old ones used instead.
```

å¤„ç†

```sh
grep -ri "mirrors.aliyun.com" /etc/apt/sources.list.d/

# ä½¿ç”¨ sed æ³¨é‡Šç›¸å…³è¡Œï¼ˆä»¥å¤‡ä»½æ–‡ä»¶å½¢å¼æ“ä½œï¼‰
sudo sed -i.bak '/mirrors.aliyun.com/docker-ce/d' /etc/apt/sources.list

# å¯¼å‡ºæ—§å¯†é’¥åˆ°æ–°è·¯å¾„
sudo apt-key export 7EA0A9C3F273FCD8 | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

sudo sed -i 's#deb [arch=amd64]#deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg]#g' /etc/apt/sources.list.d/docker-ce.list

sudo rm -rf /var/lib/apt/lists/*
sudo apt-get update

# åˆ é™¤æ®‹ç•™çš„é˜¿é‡Œäº‘æºæ–‡ä»¶
sudo rm -f /etc/apt/sources.list.d/third-party.sources /etc/apt/sources.list.d/docker.list

# ç¡®ä¿ /etc/apt/sources.list ä¸­æ— é˜¿é‡Œäº‘ Docker CE ç›¸å…³è¡Œï¼š
sudo sed -i '/mirrors.aliyun.com/docker-ce/d' /etc/apt/sources.list

# è¿ç§»æ—§å¯†é’¥åˆ°æ–°è·¯å¾„
# å¯¼å‡ºæ—§å¯†é’¥å¹¶è½¬æ¢ä¸ºæ–°æ ¼å¼
sudo apt-key export 7EA0A9C3F273FCD8 | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
# åˆ é™¤æ—§å¯†é’¥
sudo apt-key del 7EA0A9C3F273FCD8

# æ›´æ–°æ¸…åæºé…ç½®â€‹ ä¿®æ”¹ /etc/apt/sources.list.d/docker-ce.listï¼Œç¡®ä¿ signed-by å‚æ•°æŒ‡å‘æ–°å¯†é’¥è·¯å¾„ï¼š
sudo sed -i 's#signed-by=/etc/apt/keyrings/docker.gpg#signed-by=/usr/share/keyrings/docker-archive-keyring.gpg#g' /etc/apt/sources.list.d/docker-ce.list

# å¼ºåˆ¶åˆ·æ–°ä»“åº“ç¼“å­˜
sudo rm -rf /var/lib/apt/lists/*
sudo apt-get update

# 1. å¯¼å‡ºæ—§å¯†é’¥åˆ°æ–°è·¯å¾„
sudo apt-key export 7EA0A9C3F273FCD8 | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# 2. åˆ é™¤æ—§å¯†é’¥
sudo apt-key del 7EA0A9C3F273FCD8

# 3. æ›´æ–° Docker æºé…ç½®
sudo sed -i 's#deb \[arch=amd64#deb \[arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg#g' /etc/apt/sources.list.d/docker-ce.list




# ---------------------------------------------------------------------------------

# éªŒè¯ä¿®å¤æ•ˆæœ
sudo apt-get update
sudo apt update
# ç¡®è®¤ Docker CE æºçŠ¶æ€
apt-cache policy docker-ce

# æ˜¾ç¤ºå€™é€‰ç‰ˆæœ¬ä¸º 5:28.0.1-1~ubuntu.24.04~nobleï¼Œä¸”æºåœ°å€æŒ‡å‘æ¸…åé•œåƒï¼Œè¯´æ˜é…ç½®å·²ç”Ÿæ•ˆ

```



#### Â· open webui ç™½å±é—®é¢˜è§£å†³

å‚è€ƒï¼šhttps://blog.csdn.net/xianciSele/article/details/145340554

https://blog.kazoottt.top/posts/openwebui-long-loading-white-screen-solution/

https://github.com/open-webui/open-webui/discussions/7769

![å¾®ä¿¡å›¾ç‰‡_20250310084150](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250310084150.png)

```sh
# ä»ç½‘é¡µè®¿é—® 3000ç«¯å£ ç½‘é¡µç™½æ¿ï¼Œè¦ç­‰2åˆ†é’Ÿï¼Œå…¶å®æ˜¯å› ä¸º è®¿é—® openip è·å–æ¨¡å‹å¤±è´¥ï¼Œç½‘ä¸é€šã€‚

# è§£å†³æ–¹æ³•1:
# åœ¨docker-compose.yml ä¸­åŠ å¤–éƒ¨hostã€‚
 extra_hosts:
      - "api.openai.com:127.0.0.1"  
      
# è§£å†³æ–¹æ³•2:
# docker runå‘½ä»¤å¯åŠ¨çš„æ—¶å€™é…ç½®ç¯å¢ƒå˜é‡ 
 -e ENABLE_OPENAI_API=0 \  
 # æˆ–è€…docker compose æ—¶å¦‚ä¸‹
 environment:
   - ENABLE_OPENAI_API=0
-------------------------------------------------------------
name: openwebui
services:
    open-webui:
        ports:
            - 3000:8080
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: all
                          capabilities:
                              - gpu
        extra_hosts:
            - host.docker.internal:host-gateway
        volumes:
            - open-webui:/app/backend/data
        container_name: open-webui
        restart: always
        image: ghcr.io/open-webui/open-webui:cuda
        environment:
            - ENABLE_OPENAI_API=0
volumes:
    open-webui:
        external: true
        name: open-webui
```

ä»¥ä¸Šçš„ä¾‹å­éƒ½æ˜¯åœ¨ollamaä¸‹è½½çš„deepseekçš„å¤„ç†åŠæ³•ï¼Œåœ¨vllm ç›´æ¥ä¸‹è½½ deepseekæ¨¡å‹åˆ°æœ¬åœ°çš„æ–¹æ³•ä¸­ä¸€å®šè¦æ‰“å¼€openaai çš„æ”¯æŒï¼Œåªä¸è¿‡åœ¨å…·ä½“çš„url è¦æŒ‡å®šè¦æœ¬åœ°å°±å¥½äº†ã€‚å¯ä»¥çœ‹çœ‹å‰é¢vllmçš„éƒ¨ç½²ä¾‹å­ã€‚


#### Â· searxngä¸­é•¿å¥å­ä¸èƒ½æœç´¢çš„é—®é¢˜

å¼€å¯ å¤šä¸ªå›½å†…èƒ½ç”¨çš„æœç´¢å¼•æ“ï¼Œè€Œä¸æ˜¯åªå¼€ä¸€ä¸ªbingã€‚å¯ä»¥è§£å†³ã€‚bing æœç´¢å¼•æ“å¥½åƒä¸æ”¯æŒé•¿å¥çš„æœç´¢ã€‚



#### Â· å®¹å™¨é—´é€šä¿¡é—®é¢˜çš„æœ€ä½³å®è·µ

```sh
# åˆ›å»ºä¸€ä¸ªå¤–éƒ¨ç½‘ç»œ
docker network create vllm-network
```

åœ¨æ¯ä¸ª docker-compose æ–‡ä»¶ä¸­å¼•ç”¨è¿™ä¸ªç½‘ç»œã€‚ä¾‹å¦‚ï¼Œåœ¨ vllm çš„ docker-compose.yml æ–‡ä»¶ä¸­æ·»åŠ ï¼š

external: true è¡¨ç¤ºä½¿ç”¨å·²å­˜åœ¨çš„å¤–éƒ¨ç½‘ç»œï¼Œè€Œä¸æ˜¯ç”±å½“å‰çš„ Compose æ–‡ä»¶åˆ›å»ºæ–°çš„ç½‘ç»œã€‚

```yaml
networks:
  my-network:
    external: true 
    name: my-shared-network
```

ç„¶ååœ¨å¯¹åº”çš„æœåŠ¡é…ç½®ä¸­åŠ å…¥ï¼š

```yaml
services:
  open-webui:
    # ...ç°æœ‰é…ç½®...
    networks:
      - my-network
```

**ä¿®æ”¹ open-webui çš„ API åœ°å€**ï¼š
å°† `OPENAI_API_BASE_URL` è®¾ç½®ä¸º `http://vllm-openai:8000/v1`ã€‚è¿™æ · open-webui å®¹å™¨ä¼šé€šè¿‡ DNS æŸ¥æ‰¾åŒä¸€ç½‘ç»œä¸­çš„ vllm-openai æœåŠ¡ã€‚

> è¿™ç§æ–¹æ³•æ¯”è¾ƒç¨³å®šï¼ŒæœåŠ¡é—´äº’è®¿ä¸ä¾èµ–å®¿ä¸»æœº IPã€‚
> åœ¨ Docker Compose ä¸­ï¼ŒæœåŠ¡åç§°ï¼ˆåœ¨ yml æ–‡ä»¶ä¸­ services ä¸‹çš„é”®åï¼‰å°±æ˜¯å®¹å™¨åœ¨åŒä¸€ç½‘ç»œä¸­çš„ DNS åç§°ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå³ä½¿ä½ è®¾ç½®äº† container_name ä¸º deepseek-containerï¼ŒDocker å†…éƒ¨ä»ç„¶ä¼šå°†è¿™ä¸ªå®¹å™¨æ³¨å†Œä¸ºæœåŠ¡å **vllm-openai**ï¼Œæ‰€ä»¥å…¶ä»–åŒç½‘ç»œçš„å®¹å™¨å¯ä»¥é€šè¿‡ â€œvllm-openaiâ€ æ¥è®¿é—®å®ƒã€‚

å°†å¤šä¸ªå®¹å™¨åŠ å…¥åŒä¸€ä¸ªè‡ªå®šä¹‰ç½‘ç»œåï¼š

1. **å®¹å™¨ä¸å®¿ä¸»æœºä¹‹é—´çš„ç«¯å£æ˜ å°„ï¼š** è‡ªå®šä¹‰ç½‘ç»œä¸ä¼šå½±å“å®¹å™¨ä¸å®¿ä¸»æœºä¹‹é—´çš„ç«¯å£æ˜ å°„ã€‚ç«¯å£æ˜ å°„æ˜¯åœ¨å®¹å™¨å¯åŠ¨æ—¶é€šè¿‡ `-p` å‚æ•°æˆ–åœ¨ Compose æ–‡ä»¶ä¸­é€šè¿‡ `ports` æŒ‡å®šçš„ï¼Œç”¨äºå°†å®¿ä¸»æœºçš„ç‰¹å®šç«¯å£è½¬å‘åˆ°å®¹å™¨çš„ç«¯å£ã€‚è¿™äº›æ˜ å°„åœ¨è‡ªå®šä¹‰ç½‘ç»œä¸­ä»ç„¶æœ‰æ•ˆã€‚
2. **å®¹å™¨è¿æ¥äº’è”ç½‘ï¼š** é»˜è®¤æƒ…å†µä¸‹ï¼ŒDocker ä½¿ç”¨ `bridge` ç½‘ç»œé©±åŠ¨ç¨‹åºåˆ›å»ºçš„è‡ªå®šä¹‰ç½‘ç»œå…è®¸å®¹å™¨è®¿é—®å¤–éƒ¨äº’è”ç½‘ã€‚å› æ­¤ï¼Œå®¹å™¨åŠ å…¥è‡ªå®šä¹‰ç½‘ç»œåï¼Œé€šå¸¸ä»èƒ½è¿æ¥äº’è”ç½‘ã€‚ä½†å¦‚æœä½¿ç”¨å…¶ä»–ç½‘ç»œé©±åŠ¨ç¨‹åºï¼ˆå¦‚ `macvlan`ï¼‰ï¼Œå¯èƒ½éœ€è¦é¢å¤–é…ç½®ä»¥ç¡®ä¿äº’è”ç½‘è¿æ¥ã€‚

#### Â· æ— æ³•ç§‘å­¦ä¸Šç½‘ä½¿ç”¨dockeræŠ€å·§

åœ¨èƒ½ç§‘å­¦ä¸Šç½‘çš„æœºå™¨ ä¸‹è½½ä¸‹æ¥é•œåƒï¼Œæ‰“åŒ…æˆ .tar æ–‡ä»¶ï¼Œå¤åˆ¶åˆ°ä¸èƒ½ç§‘å­¦ä¸Šç½‘çš„æœºå™¨ä¸­ï¼›

æŒ‰ç…§ä¸‹é¢ä¾‹å­æ“ä½œ

```sh
 # åœ¨èƒ½ç§‘å­¦ä¸Šç½‘çš„æœºå™¨ ä¸‹è½½ä¸‹æ¥é•œåƒï¼Œæ‰“åŒ…æˆ .tar æ–‡ä»¶
 docker save -o vllm.tar vllm/vllm-openai:dddddddddddd
 
 # åœ¨ä¸èƒ½ç§‘å­¦ä¸Šç½‘çš„æœºå™¨æ‰§è¡Œ
 docker load -i vllm.tar
```

#### Â· vllmé›†ç¾¤é‡åˆ° GLOOã€NCCL æŠ¥é”™

![å¾®ä¿¡å›¾ç‰‡_20250330215009](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330215009.png)

![å¾®ä¿¡å›¾ç‰‡_20250330215013](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330215013.png)

å…ˆçœ‹çœ‹ip ç”¨çš„å“ªä¸ªç½‘å£ï¼›

ç„¶ååœ¨ run_cluster.sh è„šæœ¬ä¸­åŠ å…¥ `-e GLOO_SOCKET_IFNAME=å¯¹åº”ç½‘å£  -e NCCL_SOCKET_IFNAME=å¯¹åº”ç½‘å£` ç¯å¢ƒå˜é‡ã€‚

#### Â· vllmé›†ç¾¤é‡åˆ° The model's max seq æŠ¥é”™

![å¾®ä¿¡å›¾ç‰‡_20250330215145](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330215145.png)

ç»™æˆ‘ä»¬æç¤ºäº† ` Try increasing gpu_memory_utilization or decreasing max_model_len when initializing the engine. [repeated 2x across cluster]`

å¯ä»¥ä»è¿è¡Œ vllm serve åçš„ æç¤ºä¸­çœ‹åˆ°å…¨éƒ¨çš„ args å‚æ•°è¡¨ä¸­

![å¾®ä¿¡å›¾ç‰‡_20250330220106](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330220106.png)

æ‰¾ gpu_memory_utilizationã€max_model_lenã€‚

å¦‚ä¸Šå›¾æ˜¾ç¤ºï¼Œç¡¬ä»¶åªèƒ½æ”¯æŒåˆ°  ` KV cache (69040)` äºæ˜¯æˆ‘ä»¬æŠŠ å‚æ•°åŠ ä¸Š

```sh
 vllm serve /model/deepseek-r1-70b-AWQ \
     --tensor-parallel-size 2 \
     --pipeline-parallel-size 2 \
     --max_model_len 69040
```

#### Â· vllmé›†ç¾¤é‡åˆ° CUDA out of memory æŠ¥é”™

![å¾®ä¿¡å›¾ç‰‡_20250330221123](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330221123.png)

æ€æ­»å ç”¨æ˜¾å­˜å¤šçš„è¿›ç¨‹ï¼Œç„¶å

```sh
 vllm serve /model/deepseek-r1-70b-AWQ \
     --tensor-parallel-size 2 \
     --pipeline-parallel-size 2 \
     --max_model_len 69040 \
     --gpu-memory-utilization 0.8
```

#### Â· open webUIçŸ¥è¯†åº“ä¸Šä¼ æ–‡ä»¶é‡åˆ° ä¸Šä¼  æŠ¥é”™

`Extracted content is not available for this file. Please ensure that the file is processed before proceeding.`

è¿›å…¥ åµŒå…¥å¼æ¨¡å‹å®¹å™¨ä¸­ï¼ŒæŸ¥çœ‹æ—¥å¿—ï¼Œæœ‰å¯èƒ½æ˜¯ truncate æ²¡æœ‰åˆ‡ï¼Œå¯¼è‡´çš„ è¶…è¿‡äº† æœ€å¤§æ‰¿å—tokenã€‚

åœ¨ åµŒå…¥æ¨¡å‹å®¹å™¨çš„ yml æ–‡ä»¶ä¸­ é…ç½® è‡ªåŠ¨åˆ‡åˆ†åŠŸèƒ½å‚æ•°ï¼Œå‚è€ƒ HuggingFace Text Embeddings Inference å®˜ç½‘GitHub å³å¯ã€‚

#### Â· RAG æ—¶é‡åˆ°äº† Please reduce the length of the messages æŠ¥é”™

![å¾®ä¿¡å›¾ç‰‡_20250402181036](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250402181036.png)

æˆ‘ä»¬å³ä½¿åœ¨vLLMä¸­è®¾ç½®äº†`max-model-len 53520`ï¼Œä¹Ÿå¯èƒ½åœ¨ragæ—¶æŠ¥è¿™æ ·çš„é”™è¯¯ï¼›

å› ä¸ºï¼š

**RAGçš„ä¸Šä¸‹æ–‡å åŠ ç‰¹æ€§**
RAGç³»ç»Ÿä¼šå°†æ£€ç´¢åˆ°çš„çŸ¥è¯†åº“å†…å®¹ç›´æ¥æ‹¼æ¥åˆ°ç”¨æˆ·è¾“å…¥ä¸­ï¼ˆç§°ä¸ºâ€œå¢å¼ºâ€ï¼‰ã€‚è‹¥çŸ¥è¯†åº“æ–‡æ¡£åˆ†å—è¿‡å¤§æˆ–æ£€ç´¢ç»“æœè¿‡å¤šï¼Œå³ä½¿åŸå§‹ç”¨æˆ·æé—®å¾ˆçŸ­ï¼Œæœ€ç»ˆè¾“å…¥ä¹Ÿä¼šå‘ˆç°â€œç”¨æˆ·é—®é¢˜+å¤šç¯‡é•¿æ–‡æ¡£â€çš„ç»“æ„ã€‚ä¾‹å¦‚ï¼š

- ç”¨æˆ·è¾“å…¥ï¼š50 tokens
- æ£€ç´¢åˆ°3ç¯‡æ–‡æ¡£ï¼Œæ¯ç¯‡2000 tokens
- æ€»è¾“å…¥é‡ï¼š50 + 3Ã—2000 = 6050 tokens

è§£å†³åŠæ³•ï¼š

**æ»‘åŠ¨çª—å£åˆ†å—**ï¼šå°†é•¿æ–‡æ¡£æŒ‰500-800 tokensä¸ºå•ä½åˆ†å‰²ï¼Œé‡å ç‡å»ºè®®15%ï¼Œå¦‚æ¯å—ä¿ç•™å‰ä¸€å—çš„75 tokensã€‚

**é™åˆ¶å¬å›å†…å®¹è§„æ¨¡**ï¼šè®¾ç½®Top-Ké˜ˆå€¼ï¼Œä»…ä¿ç•™ç›¸å…³æ€§æœ€é«˜çš„3-5ä¸ªçŸ¥è¯†å—ã€‚

åœ¨open webUI ä¸­è®¾ç½®ã€‚

![å¾®ä¿¡å›¾ç‰‡_20250402181950](%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250402181950.png)

ç„¶åé‡æ–°ä¼ ä¸€ä¸‹ çŸ¥è¯†åº“ä¸­çš„æ–‡æ¡£ã€‚

